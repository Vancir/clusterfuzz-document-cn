{"0": {
    "doc": "FAQ",
    "title": "What languages does ClusterFuzz support?",
    "content": "ClusterFuzz definitely supports C, C++ when compiled with clang. It has also been tested with Rust and may work with other languages that can be compiled with an LLVM-based toolchain (e.g. Swift). ",
    "url": "/clusterfuzz-document-cn/reference/faq/#what-languages-does-clusterfuzz-support",
    "relUrl": "/reference/faq/#what-languages-does-clusterfuzz-support"
  },"1": {
    "doc": "FAQ",
    "title": "Why is an LLVM-based toolchain needed for full support?",
    "content": "An LLVM-based toolchain is needed for full ClusterFuzz support for two reasons: . | Because ClusterFuzz relies on LLVM sanitizers for detecting and identifying bugs. | Because use of libFuzzer and AFL in ClusterFuzz requires coverage instrumentation only LLVM can provide. | . ",
    "url": "/clusterfuzz-document-cn/reference/faq/#why-is-an-llvm-based-toolchain-needed-for-full-support",
    "relUrl": "/reference/faq/#why-is-an-llvm-based-toolchain-needed-for-full-support"
  },"2": {
    "doc": "FAQ",
    "title": "What if I really don’t want to use an LLVM-based toolchain?",
    "content": "We strongly recommend using an LLVM-based toolchain. That said, you may be able to use some parts of ClusterFuzz with GCC or extend ClusterFuzz to support your use of GCC. However, if you do this, you are in unexplored territory and we can not support this. GCC may work for blackbox fuzzing without modifying ClusterFuzz since GCC supports ASan. Using GCC with AFL or libFuzzer would probably require considerable changes to ClusterFuzz to get working. In the end, it is probably easier to make whatever changes are needed to build with clang. ",
    "url": "/clusterfuzz-document-cn/reference/faq/#what-if-i-really-dont-want-to-use-an-llvm-based-toolchain",
    "relUrl": "/reference/faq/#what-if-i-really-dont-want-to-use-an-llvm-based-toolchain"
  },"3": {
    "doc": "FAQ",
    "title": "Why isn’t $MY_LANGUAGE supported?",
    "content": "In theory, ClusterFuzz is language agnostic and can be extended to support fuzzing code written in any language. In practice though, it is less easy to find interesting bugs in memory safe languages so ClusterFuzz doesn’t have support for fuzzing most of them. ",
    "url": "/clusterfuzz-document-cn/reference/faq/#why-isnt-my_language-supported",
    "relUrl": "/reference/faq/#why-isnt-my_language-supported"
  },"4": {
    "doc": "FAQ",
    "title": "FAQ",
    "content": ". | What languages does ClusterFuzz support? . | Why is an LLVM-based toolchain needed for full support? | What if I really don’t want to use an LLVM-based toolchain? | Why isn’t $MY_LANGUAGE supported? | . | . ",
    "url": "/clusterfuzz-document-cn/reference/faq/",
    "relUrl": "/reference/faq/"
  },"5": {
    "doc": "Access control",
    "title": "Access control",
    "content": "This page explains how you can restrict access to various parts of the ClusterFuzz web interface. This is controlled by defining the user(s) as part of one of the following groups. | Access control . | Regular users | Privileged users | Administrators | . | . ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/advanced/access-control/",
    "relUrl": "/using-clusterfuzz/advanced/access-control/"
  },"6": {
    "doc": "Access control",
    "title": "Regular users",
    "content": "Regular users are usually the developers in your project, who triage and fix bugs. They can access most pages of the ClusterFuzz web interface, but with restricted permissions. This includes: . | Testcases page (excluding security vulnerabilities) | Testcase report page (excluding security vulnerabilities) | Crash statistics page (excluding security vulnerabilities) | Crashes by range page (excluding security vulnerabilities) | Fuzzer statistics page | Upload testcase page | Fuzzers page (view only) | Corpora page (view only) | Bots page | . They do not have access to the following pages: . | Job page | Configuration page | . ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/advanced/access-control/#regular-users",
    "relUrl": "/using-clusterfuzz/advanced/access-control/#regular-users"
  },"7": {
    "doc": "Access control",
    "title": "Privileged users",
    "content": "Privileged users have unrestricted access to most parts of ClusterFuzz. These users can access all pages that a regular user can. However, privileged users can also: . | Access security bugs (Security: “YES” in report). | Upload new fuzzers on Fuzzers page. | Upload new corpora on Corpora page. | Create new jobs on Jobs page. | . Privileged users are defined by the Administrators on the Configuration page. ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/advanced/access-control/#privileged-users",
    "relUrl": "/using-clusterfuzz/advanced/access-control/#privileged-users"
  },"8": {
    "doc": "Access control",
    "title": "Administrators",
    "content": "An administrator has access to all parts of the ClusterFuzz web interface. This includes everything a privileged user has access to, and also includes: . | Access to the Configuration page. | Setting user permissions using: . | “Privileged Users” (e.g. user@example.com). | “User permissions” section. | . | . | . ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/advanced/access-control/#administrators",
    "relUrl": "/using-clusterfuzz/advanced/access-control/#administrators"
  },"9": {
    "doc": "Advanced features",
    "title": "Advanced features",
    "content": "这些文档详细介绍了ClusterFuzz的一些高阶功能. ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/advanced/",
    "relUrl": "/using-clusterfuzz/advanced/"
  },"10": {
    "doc": "Analyzing fuzzer performance",
    "title": "Analyzing fuzzer performance",
    "content": "ClusterFuzz automates fuzzing as much as possible, but it’s the responsibility of users to write and maintain fuzzers that can find security bugs. This page gives recommendations on how to analyze the performance of the fuzzers running on ClusterFuzz. Note: this page only applies to fuzz targets doing coverage guided fuzzing with libFuzzer or AFL. | Analyzing fuzzer performance . | When to analyze fuzz target performance | Performance factors | Fuzzer stats | Performance report | Coverage report | Fuzzer logs | . | . ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/workflows/analyzing-fuzzing-performance/",
    "relUrl": "/using-clusterfuzz/workflows/analyzing-fuzzing-performance/"
  },"11": {
    "doc": "Analyzing fuzzer performance",
    "title": "When to analyze fuzz target performance",
    "content": "It’s important to regularly monitor the performance of fuzz targets, especially after a new target is created. If a target finds many new crashes, fixing them is probably more important than analyzing performance. But if a target has not found any crashes in a while, you should probably examine its performance. ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/workflows/analyzing-fuzzing-performance/#when-to-analyze-fuzz-target-performance",
    "relUrl": "/using-clusterfuzz/workflows/analyzing-fuzzing-performance/#when-to-analyze-fuzz-target-performance"
  },"12": {
    "doc": "Analyzing fuzzer performance",
    "title": "Performance factors",
    "content": ". | Speed is crucial for fuzzing. There is no minimum threshold. The faster a fuzz target generates testcases, the better. | Code coverage should grow over time. A fuzz target should be continuously generating new “interesting” testcases that exercise various parts of the target program. | Blocking issues should be resolved. If a fuzz target frequently reports a Timeout, Out-of-Memory, or other crashes, it will be blocking the target from finding more interesting issues. | . ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/workflows/analyzing-fuzzing-performance/#performance-factors",
    "relUrl": "/using-clusterfuzz/workflows/analyzing-fuzzing-performance/#performance-factors"
  },"13": {
    "doc": "Analyzing fuzzer performance",
    "title": "Fuzzer stats",
    "content": "The Fuzzer stats page provides metrics on fuzzer performance. Using the filters on the page, you can see how those metrics (e.g. execution speed or number of crashes) change over time (if you choose “Group by Day”). You can compare different fuzzers to one another using “Group by Fuzzer”. There is also a “Group by Time” filter that shows fuzzer stats as charts rather than raw numbers. This feature requires a production setup, as fuzzer stats are stored in BigQuery. The stats are usually delayed by up to 24 hours, as data is uploaded to BigQuery once a day. ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/workflows/analyzing-fuzzing-performance/#fuzzer-stats",
    "relUrl": "/using-clusterfuzz/workflows/analyzing-fuzzing-performance/#fuzzer-stats"
  },"14": {
    "doc": "Analyzing fuzzer performance",
    "title": "Performance report",
    "content": "ClusterFuzz provides automatically generated performance reports that identify performance issues and give recommendations on how those issues can be resolved. The reports also prioritize issues and provide fuzzer logs that demonstrate the issues. ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/workflows/analyzing-fuzzing-performance/#performance-report",
    "relUrl": "/using-clusterfuzz/workflows/analyzing-fuzzing-performance/#performance-report"
  },"15": {
    "doc": "Analyzing fuzzer performance",
    "title": "Coverage report",
    "content": "Code coverage is a very important metric for evaluating fuzzer performance. Looking at the code coverage report, you can see which exact parts of the target program are tested by the fuzzer and which parts are never executed. If you set up a code coverage builder for ClusterFuzz, you can find links to the coverage reports on the Fuzzer stats page. Otherwise, you can generate code coverage reports locally. For C and C++ targets, we recommend using Clang Source-based Code Coverage. ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/workflows/analyzing-fuzzing-performance/#coverage-report",
    "relUrl": "/using-clusterfuzz/workflows/analyzing-fuzzing-performance/#coverage-report"
  },"16": {
    "doc": "Analyzing fuzzer performance",
    "title": "Fuzzer logs",
    "content": "If none of the above gives you enough information about fuzzer performance, looking into the fuzzer logs may help. On the fuzzer stats page, you can find a link to the GCS bucket storing the logs. You can also navigate to that manually using the Google Cloud Storage web interface. ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/workflows/analyzing-fuzzing-performance/#fuzzer-logs",
    "relUrl": "/using-clusterfuzz/workflows/analyzing-fuzzing-performance/#fuzzer-logs"
  },"17": {
    "doc": "Architecture",
    "title": "Architecture",
    "content": ". ClusterFuzz提供了一个自动化的端到端基础设施, 用于查找和分类崩溃, 最大程度地减少崩溃的重现, 二分选择和验证修复代码. | Supported platforms | Requirements . | Local instance | . | Operation . | App Engine | Fuzzing Bots | . | . ",
    "url": "/clusterfuzz-document-cn/architecture/",
    "relUrl": "/architecture/"
  },"18": {
    "doc": "Architecture",
    "title": "Supported platforms",
    "content": "ClusterFuzz使用Python编写. 它可运行在Linux, macOS, 和 Windows平台上. ",
    "url": "/clusterfuzz-document-cn/architecture/#supported-platforms",
    "relUrl": "/architecture/#supported-platforms"
  },"19": {
    "doc": "Architecture",
    "title": "Requirements",
    "content": "ClusterFuzz运行在Google Cloud Platform, 并且依赖了多种服务: . | Compute Engine (并非绝对需要. Fuzzing bots可在任何地方运行.) | App Engine | Cloud Storage | Cloud Datastore | Cloud Pub/Sub | BigQuery | Stackdriver日志记录及监控 | . 注意: 我们当前仅支持使用托管了Chromium的Monorail作为Bug跟踪器. 将来会增加对自定义Bug跟踪器对支持. Local instance . 通过使用本地的Google Cloud模拟器, 您可以在没有这些依赖项的情况下在本地运行ClusterFuzz. 但如果使用模拟器的话, 某些依赖BigQuery和Stackdriver的功能会因为缺少模拟器支持而被禁用. 注意: 本地实例仅支持Linux和macOS平台. ",
    "url": "/clusterfuzz-document-cn/architecture/#requirements",
    "relUrl": "/architecture/#requirements"
  },"20": {
    "doc": "Architecture",
    "title": "Operation",
    "content": "ClusterFuzz包含有两大主要组件: . | App Engine 实例 | 模糊测试机器人池 | . App Engine . App Engine实例提供了一个Web界面来获取崩溃信息, 统计信息和其他信息. 它还负责安排定时任务. Fuzzing Bots . 模糊机器人负责从所在平台对应到任务队列中获取任务并运行, 机器人主要运行的任务有: . | fuzz: 运行一个模糊测试的会话. | progression: 检查一个测试用例是否依然可以重现崩溃或者已经修复. | regression: 计算引入崩溃的代码修订范围. | minimize: 执行测试用例最小化. | corpus_pruning: 根据覆盖率将语料库缩减到最小(仅限libFuzzer). | analyze: 针对某个任务手动上传测试用例并运行, 查看其是否会崩溃. | . ClusterFuzz上包括两种机器人: . | 抢占式: 抢占式机器可以随时关闭, 并且只能运行fuzz任务. 云供应商通常以更低廉的价格提供抢占式实例, 因此我们建议使用这种类型的机器人进行扩展. | 非抢占式: 非抢占式机器不应被关闭, 它可以运行所有功能的任务, 包括必须不间断运行的关键性任务比如progression. | . ",
    "url": "/clusterfuzz-document-cn/architecture/#operation",
    "relUrl": "/architecture/#operation"
  },"21": {
    "doc": "Blackbox fuzzing",
    "title": "Blackbox fuzzing",
    "content": "本页面将引导您设置第一个黑盒fuzzer. | Blackbox fuzzing . | Providing builds | Creating a job type | Uploading a fuzzer | Checking results | . | . ",
    "url": "/clusterfuzz-document-cn/setting-up-fuzzing/blackbox-fuzzing/",
    "relUrl": "/setting-up-fuzzing/blackbox-fuzzing/"
  },"22": {
    "doc": "Blackbox fuzzing",
    "title": "Providing builds",
    "content": "开始模糊测试之前, 您需要使用sanitizer构建目标代码. AddressSanitizer是目前最常用于模糊测试的的sanitizer, 它通过代码插装来检查内存安全性问题. Clang是其支持的编译器, GCC应该也受支持, 选用那个编译器则具体取决于项目的构建系统. 简单来说, 就是需要将-fsanitize=address标志添加到您的C/C++编译器和链接器标志中去. ",
    "url": "/clusterfuzz-document-cn/setting-up-fuzzing/blackbox-fuzzing/#providing-builds",
    "relUrl": "/setting-up-fuzzing/blackbox-fuzzing/#providing-builds"
  },"23": {
    "doc": "Blackbox fuzzing",
    "title": "Creating a job type",
    "content": "作业的类型是用于描述如何运行特定目标程序进行模糊测试的规范. 它由环境变量值组成. 作业的名称非常重要, 并且必须要包含 “asan”, “msan”, “ubsan”或 “tsan” 关键字, 具体取决于您使用的sanitizer. 比如一个有效名称可以是 “asan_linux_app”. 一个基本的二进制 “app” 作业类型可能类似于以下这样: . APP_NAME = app APP_ARGS = --some_interesting_option --some_very_important_option REQUIRED_APP_ARGS = --some_very_important_option CUSTOM_BINARY = True TEST_TIMEOUT = 30 . 拆分来看, . | APP_NAME表示目标程序的名称. | APP_ARGS是要传递给目标应用程序的参数. 此变量应包含您想要传递的必需参数和可选参数. | REQUIRED_APP_ARGS是指必须传递给目标应用程序的参数, 并且这些参数将始终被使用. 而其他在APP_ARGS中指定的参数以及未在此处指定的参数, 如果在最小化测试用例过程中发现该参数并不会影响崩溃的重新, 那么就会被ClusterFuzz进行移除. | CUSTOM_BINARY指是否使用用户上传的归档文件, 而不是从GCS存储桶中拉取文件. | TEST_TIMEOUT是每个测试用例的最大超时时间(以秒为单位). | . 要创建一个作业: . | 导航到Jobs页面. | 转到”ADD NEW JOB”表单. | 填写表单里的”Name”和”Platform”. | 选择您构建好的程序(以zip进行打包, 同时zip包内还需要包含待测试的目标二进制文件)并作为”Custom Build”上传. | 使用”ADD”按钮将作业添加到ClusterFuzz. | . ",
    "url": "/clusterfuzz-document-cn/setting-up-fuzzing/blackbox-fuzzing/#creating-a-job-type",
    "relUrl": "/setting-up-fuzzing/blackbox-fuzzing/#creating-a-job-type"
  },"24": {
    "doc": "Blackbox fuzzing",
    "title": "Uploading a fuzzer",
    "content": "ClusterFuzz中的黑盒fuzzer是指一个程序, 它接受语料库作为输入, 并将变异或生成的测试用例输出到输出目录. 该程序必须采用以下命名参数: . | --input_dir &lt;directory&gt;. 这里指定输入目录, 目录包含给定Fuzzer的语料库. | --output_dir &lt;directory&gt;. 这里指定输出目录, 目录包含Fuzzer的写入数据. | --no_of_files &lt;n&gt;. 这里会限制Fuzzer向输出目录写入测试用例的数量. | . 由Fuzzer生成的测试用例文件名必须以前缀fuzz-进行命名. 这有助于ClusterFuzz知道哪些是需要进行模糊测试的的文件. 输出目录还必须包含执行测试用例所需的所有依赖项. 该Fuzzer的执行入口应该是一个以run开头命名的文件. 例如, 使用Python编写的Fuzzer可能名为run.py. 要将其上传到ClusterFuzz, 请将Fuzzer连同其依赖项一起打包到一个zip压缩包内, 然后： . | 导航到Fuzzers页面。 | 点击”CREATE NEW”按钮. | 填写Fuzzer的”Name”. | 选择要上传的Fuzzer压缩包. | 点击”Select/modify jobs”. | 标记上面创建的作业. | 点击”SUBMIT” | . ",
    "url": "/clusterfuzz-document-cn/setting-up-fuzzing/blackbox-fuzzing/#uploading-a-fuzzer",
    "relUrl": "/setting-up-fuzzing/blackbox-fuzzing/#uploading-a-fuzzer"
  },"25": {
    "doc": "Blackbox fuzzing",
    "title": "Checking results",
    "content": "Bots需要花一些时间来启动您上传的Fuzzer. 您可以通过Bots页面来检查哪些Bot正在运行您的Fuzzer. 一旦Bot运行完您的模糊器, 您就可以访问Fuzzers页面(请参阅第二列)查看运行过程的控制台输出和测试用例. 您也可以检查Bot日志. ",
    "url": "/clusterfuzz-document-cn/setting-up-fuzzing/blackbox-fuzzing/#checking-results",
    "relUrl": "/setting-up-fuzzing/blackbox-fuzzing/#checking-results"
  },"26": {
    "doc": "Build pipeline",
    "title": "Build pipeline",
    "content": "This document describes the requirements and recommendations for setting up a continuous build pipeline for a project using ClusterFuzz. | Build pipeline . | Why do you need a build pipeline? | Setting up a builder | Sanitizers | Providing the builds to ClusterFuzz | Providing revisions for the build dependencies | Other artifacts and runtime dependencies | Build pipeline solutions | . | . ",
    "url": "/clusterfuzz-document-cn/production-setup/build-pipeline/",
    "relUrl": "/production-setup/build-pipeline/"
  },"27": {
    "doc": "Build pipeline",
    "title": "Why do you need a build pipeline?",
    "content": "Fuzzing is a software testing technique which works out best if done continuously. As your target projects evolve, ClusterFuzz needs to be able to fuzz the most recent versions of them. Having a continuously running build pipeline allows ClusterFuzz to identify revisions when a regression was introduced as well as detect bug fixes and the corresponding revisions. ",
    "url": "/clusterfuzz-document-cn/production-setup/build-pipeline/#why-do-you-need-a-build-pipeline",
    "relUrl": "/production-setup/build-pipeline/#why-do-you-need-a-build-pipeline"
  },"28": {
    "doc": "Build pipeline",
    "title": "Setting up a builder",
    "content": "ClusterFuzz does not provide any build infrastructure, as build systems can be very different across projects. If you have existing CI infrastructure, very likely it can be used for providing builds to ClusterFuzz. ",
    "url": "/clusterfuzz-document-cn/production-setup/build-pipeline/#setting-up-a-builder",
    "relUrl": "/production-setup/build-pipeline/#setting-up-a-builder"
  },"29": {
    "doc": "Build pipeline",
    "title": "Sanitizers",
    "content": "As described in the Setting up fuzzing docs, your builds need to be instrumented with a sanitizer. See the individual links for each sanitizer here for instructions on how to use them. ",
    "url": "/clusterfuzz-document-cn/production-setup/build-pipeline/#sanitizers",
    "relUrl": "/production-setup/build-pipeline/#sanitizers"
  },"30": {
    "doc": "Build pipeline",
    "title": "Providing the builds to ClusterFuzz",
    "content": ". | The builds should be packed into zip or tar archives and uploaded to a GCS bucket. Uploading can be done via gsutil tool or by using signed URLs. | The archive name should be of any-name-([0-9]+).zip format, where ([0-9]+) stands for a revision number such as SVN commit position, a timestamp (e.g. YYYYMMDDHHMM), or another build number which increases with every build. Other than zip, we support tar extensions as well. | When setting up a fuzzing job, specify RELEASE_BUILD_BUCKET_PATH env variable to point to the builds location, e.g. gs://bucket-name/subdirectory/any-name-([0-9]+).zip. | . ",
    "url": "/clusterfuzz-document-cn/production-setup/build-pipeline/#providing-the-builds-to-clusterfuzz",
    "relUrl": "/production-setup/build-pipeline/#providing-the-builds-to-clusterfuzz"
  },"31": {
    "doc": "Build pipeline",
    "title": "Providing revisions for the build dependencies",
    "content": "ClusterFuzz is able to detect regression and fixed revision ranges not only for your target project, but for its dependencies as well. The only requirement is to provide a .srcmap.json file alongside the build archive. The filename should be the same as the build archive name, but with .srcmap.json suffix instead of .zip/.tar* (i.e. any-name-([0-9]+).srcmap.json). When setting up a fuzzing job, specify REVISION_VARS_URL env variable to point to srcmap files location, e.g. gs://bucket-name/subdirectory/any-name-([0-9]+).srcmap.json. These srcmap files have the following format: . { \"/path/to/library\": { \"type\": \"type_of_version_control_system\", \"url\": \"repository_url\", \"rev\": \"revision_identifier\", }, // any number of the projects enumerated in this format } . An example of .srcmap.json for a libpng build: . { \"/src/libpng\": { \"type\": \"git\", \"url\": \"https://github.com/glennrp/libpng.git\", \"rev\": \"eddf9023206dc40974c26f589ee2ad63a4227a1e\" }, \"/src/zlib\": { \"type\": \"git\", \"url\": \"https://github.com/madler/zlib.git\", \"rev\": \"cacf7f1d4e3d44d871b605da3b647f07d718623f\" }, \"/src/libfuzzer\": { \"type\": \"svn\", \"url\": \"https://llvm.org/svn/llvm-project/compiler-rt/trunk/lib/fuzzer\", \"rev\": \"350185\" } } . ",
    "url": "/clusterfuzz-document-cn/production-setup/build-pipeline/#providing-revisions-for-the-build-dependencies",
    "relUrl": "/production-setup/build-pipeline/#providing-revisions-for-the-build-dependencies"
  },"32": {
    "doc": "Build pipeline",
    "title": "Other artifacts and runtime dependencies",
    "content": "If your target program requires any additional runtime dependencies or artifacts such as seed corpus or a dictionary for libFuzzer or AFL, all these files should be placed in the same directory as the target executable and be included in the build archive. ",
    "url": "/clusterfuzz-document-cn/production-setup/build-pipeline/#other-artifacts-and-runtime-dependencies",
    "relUrl": "/production-setup/build-pipeline/#other-artifacts-and-runtime-dependencies"
  },"33": {
    "doc": "Build pipeline",
    "title": "Build pipeline solutions",
    "content": "Most of the Continuous Integration systems can be used for providing builds to ClusterFuzz. Examples include Google Cloud Build, Jenkins, and others. ",
    "url": "/clusterfuzz-document-cn/production-setup/build-pipeline/#build-pipeline-solutions",
    "relUrl": "/production-setup/build-pipeline/#build-pipeline-solutions"
  },"34": {
    "doc": "ClusterFuzz",
    "title": "Setting up a production project",
    "content": "This document walks you through the process of setting up a production project using ClusterFuzz. | Setting up a production project . | Prerequisites | Create a new Google Cloud project | Enable Firebase . | Web API Key | . | Create OAuth credentials | Run the project setup script | Verification | Deploying new changes | Configuring number of bots . | Other cloud providers | . | . | . ",
    "url": "/clusterfuzz-document-cn/production-setup/clusterfuzz/#setting-up-a-production-project",
    "relUrl": "/production-setup/clusterfuzz/#setting-up-a-production-project"
  },"35": {
    "doc": "ClusterFuzz",
    "title": "Prerequisites",
    "content": "Make sure to go through Prerequisites page first. ",
    "url": "/clusterfuzz-document-cn/production-setup/clusterfuzz/#prerequisites",
    "relUrl": "/production-setup/clusterfuzz/#prerequisites"
  },"36": {
    "doc": "ClusterFuzz",
    "title": "Create a new Google Cloud project",
    "content": "Follow these instructions to create a new Google Cloud Project. Verify that your project is successfully created using . gcloud projects describe &lt;your project id&gt; . Export the project id in environment for later use: . export CLOUD_PROJECT_ID=&lt;your project id&gt; . If you’re new to Google Cloud you may be eligible for trial credit. ",
    "url": "/clusterfuzz-document-cn/production-setup/clusterfuzz/#create-a-new-google-cloud-project",
    "relUrl": "/production-setup/clusterfuzz/#create-a-new-google-cloud-project"
  },"37": {
    "doc": "ClusterFuzz",
    "title": "Enable Firebase",
    "content": ". | Follow these instructions to add Firebase to the Google Cloud project you just created. This will be used for authentication and should not incur any additional charges. | In the Firebase console, go to the Auth section and enable “Google” as a Sign-in provider. | In the same section, add the domains you plan on using to the “Authorized domains” list. The default domain for App Engine looks like &lt;your project id&gt;.appspot.com. | . Web API Key . To obtain a web API key, . | Go to the Firebase console and select your project. | From the project overview page, click Add Firebase to your web app to display the customized code snippet. | Copy the apiKey value, and export it like so: | . export FIREBASE_API_KEY=&lt;your api key&gt; . ",
    "url": "/clusterfuzz-document-cn/production-setup/clusterfuzz/#enable-firebase",
    "relUrl": "/production-setup/clusterfuzz/#enable-firebase"
  },"38": {
    "doc": "ClusterFuzz",
    "title": "Create OAuth credentials",
    "content": "Follow these instructions to create OAuth credentials for our project setup script. Choose OAuth client ID credential type. When prompted for an application type, choose Desktop app. You may also need to fill in the application name on “OAuth consent screen” tab, enter any name of your choice, e.g. MyClusterFuzz. Download these credentials as JSON and place it somewhere safe. Export the path for later use: . e.g. export CLIENT_SECRETS_PATH=/path/to/your/client_secrets.json . ",
    "url": "/clusterfuzz-document-cn/production-setup/clusterfuzz/#create-oauth-credentials",
    "relUrl": "/production-setup/clusterfuzz/#create-oauth-credentials"
  },"39": {
    "doc": "ClusterFuzz",
    "title": "Run the project setup script",
    "content": "Now you can run our project setup script to automate the process of setting up a production instance of ClusterFuzz. This script also creates a config directory for you, which contains some default settings for your deployment and can be later updated. mkdir /path/to/myconfig # Any EMPTY directory outside the ClusterFuzz source repository. export CONFIG_DIR=/path/to/myconfig python butler.py create_config --oauth-client-secrets-path=$CLIENT_SECRETS_PATH \\ --firebase-api-key=$FIREBASE_API_KEY --project-id=$CLOUD_PROJECT_ID $CONFIG_DIR . This can take a few minutes to finish, so please be patient. The script also performs a test deployment to verify that the project has been successfully set up. Check out the configuration yaml files in /path/to/myconfig directory and change the defaults to suit your use cases. Some common configuration items include: . | Change the default project name using env.PROJECT_NAME attribute in project.yaml. | Add access for all users of a domain using whitelisted_domains attribute in gae/auth.yaml. | Use a custom domain for hosting (instead of appspot.com) using domains attribute in gae/config.yaml. | . It’s recommended to check your /path/to/myconfig directory into your own version control to track your configuration changes and to prevent loss. ",
    "url": "/clusterfuzz-document-cn/production-setup/clusterfuzz/#run-the-project-setup-script",
    "relUrl": "/production-setup/clusterfuzz/#run-the-project-setup-script"
  },"40": {
    "doc": "ClusterFuzz",
    "title": "Verification",
    "content": "To verify that your project is successfully deployed. | Verify that your application is accessible on https://&lt;your project id&gt;.appspot.com. If you see an error on missing datastore indexes, this may take some time to be generated after the deployment finished. You can check the status here. | Verify that the bots are successfully created using the instructions here. The defaults are 1 regular linux bot and 2 preemptible linux bots on Google Compute Engine. | . ",
    "url": "/clusterfuzz-document-cn/production-setup/clusterfuzz/#verification",
    "relUrl": "/production-setup/clusterfuzz/#verification"
  },"41": {
    "doc": "ClusterFuzz",
    "title": "Deploying new changes",
    "content": "Now that the initial setup is complete, you may deploy further changes by running: . python butler.py deploy --config-dir=$CONFIG_DIR --prod --force . ",
    "url": "/clusterfuzz-document-cn/production-setup/clusterfuzz/#deploying-new-changes",
    "relUrl": "/production-setup/clusterfuzz/#deploying-new-changes"
  },"42": {
    "doc": "ClusterFuzz",
    "title": "Configuring number of bots",
    "content": "See this page for instructions to set up the bots. Once you make changes to the clusters.yaml file, you must re-deploy by following the previous section. An App Engine cron job will periodically read the contents of this file and create or delete new instances as necessary. Other cloud providers . Note that bots do not have to run on Google Compute Engine. It is possible to run your own machines or machines with another cloud provider. To do so, those machines must be running with a service account to access the necessary Google services such as Cloud Datastore and Cloud Storage. We provide Docker images for running ClusterFuzz bots. ",
    "url": "/clusterfuzz-document-cn/production-setup/clusterfuzz/#configuring-number-of-bots",
    "relUrl": "/production-setup/clusterfuzz/#configuring-number-of-bots"
  },"43": {
    "doc": "ClusterFuzz",
    "title": "ClusterFuzz",
    "content": " ",
    "url": "/clusterfuzz-document-cn/production-setup/clusterfuzz/",
    "relUrl": "/production-setup/clusterfuzz/"
  },"44": {
    "doc": "Code coverage",
    "title": "Code coverage",
    "content": "This document describes the requirements and recommendations for enabling code coverage reports for a project using ClusterFuzz. | Code coverage . | ClusterFuzz and code coverage | Setting up a code coverage builder | Code coverage report and stats | Coverage information file | . | . ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/advanced/code-coverage/",
    "relUrl": "/using-clusterfuzz/advanced/code-coverage/"
  },"45": {
    "doc": "Code coverage",
    "title": "ClusterFuzz and code coverage",
    "content": "ClusterFuzz is capable of storing, presenting, and leveraging code coverage information. However, ClusterFuzz does not generate code coverage reports, as that process depends on the build system used by a project, and build systems can be very different across projects. ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/advanced/code-coverage/#clusterfuzz-and-code-coverage",
    "relUrl": "/using-clusterfuzz/advanced/code-coverage/#clusterfuzz-and-code-coverage"
  },"46": {
    "doc": "Code coverage",
    "title": "Setting up a code coverage builder",
    "content": "It is possible to set up an external builder or a Continuous Integration job that would produce code coverage data for ClusterFuzz. For C and C++ projects it is recommended to use Clang Source-based Code Coverage. ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/advanced/code-coverage/#setting-up-a-code-coverage-builder",
    "relUrl": "/using-clusterfuzz/advanced/code-coverage/#setting-up-a-code-coverage-builder"
  },"47": {
    "doc": "Code coverage",
    "title": "Code coverage report and stats",
    "content": "A typical workflow for the builder is the following: . | Check out the latest version of the source code for the project. | Build all the fuzzers in the project with code coverage instrumentation. | Download the latest corpus backup from ClusterFuzz. | For every fuzzer in the project: . | Unpack the corpus backup. | Run the fuzzer against the unpacked corpus. | Process the coverage dumps (.profraw files) using llvm-profdata merge. | Use the resulting .profdata file to generate $fuzzer_name.json file via llvm-cov export -summary-only. | . | Merge all .profdata files produced by individual fuzzers into a single .profdata file using llvm-profdata merge. | Use the final .profdata file to generate summary.json file for the whole project. The resulting file will include aggregate data from the all fuzzers. | Use the final .profdata file to generate an HTML report using llvm-cov show -format=html. The report will include aggregate data from the all fuzzers. | . As a result, the builder should produce the following artifacts: . | JSON files with coverage stats for every fuzzer in the project. | JSON file with coverage stats for the whole project. | HTML report for the whole project. | . Here is an example of OSS-Fuzz code coverage job definition for Google Cloud Build. It also uses coverage_utils.py script from Chromium and this bash script. ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/advanced/code-coverage/#code-coverage-report-and-stats",
    "relUrl": "/using-clusterfuzz/advanced/code-coverage/#code-coverage-report-and-stats"
  },"48": {
    "doc": "Code coverage",
    "title": "Coverage information file",
    "content": "The builder needs to upload the artifacts and a JSON file containing coverage information to a GCS bucket specified in the project config (coverage.reports.bucket). The file name should be equal to the project name, e.g. zlib.json. The JSON file(s) must be uploaded to the following location: . gs://&lt;bucket name&gt;/latest_report_info/&lt;project name&gt;.json # Example from OSS-Fuzz: gs://oss-fuzz-coverage/latest_report_info/zlib.json . The format of the file is the following: . { \"report_date\": \"YYYYMMDD\", \"fuzzer_stats_dir\": \"gs://path_to_directory_with_per_fuzzer_summary.json_files\", \"report_summary_path\": \"gs://path_to_the_project_summary.json_file\", \"html_report_url\": \"https://link_to_the_main_page_of_the_report\", } . | report_date is the date when the report was generated. | fuzzer_stats_dir is a GCS directory containing JSON files for every fuzzer ($fuzzer_name.json). | report_summary_path should point to the summary.json file that includes aggregate data from the all fuzzers in the project. | html_report_url should point to the index.html of the HTML report. | . An example of a real zlib.json file uploaded by the code coverage job on OSS-Fuzz. { \"report_date\": \"20190112\", \"fuzzer_stats_dir\": \"gs://oss-fuzz-coverage/zlib/fuzzer_stats/20190112\", \"report_summary_path\": \"gs://oss-fuzz-coverage/zlib/reports/20190112/linux/summary.json\", \"html_report_url\": \"https://storage.googleapis.com/oss-fuzz-coverage/zlib/reports/20190112/linux/index.html\", } . ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/advanced/code-coverage/#coverage-information-file",
    "relUrl": "/using-clusterfuzz/advanced/code-coverage/#coverage-information-file"
  },"49": {
    "doc": "Contributing code",
    "title": "Contributing code",
    "content": "这些页面将引导您如何完成向ClusterFuzz贡献代码. ",
    "url": "/clusterfuzz-document-cn/contributing-code/",
    "relUrl": "/contributing-code/"
  },"50": {
    "doc": "Coverage guided vs blackbox fuzzing",
    "title": "Coverage guided vs blackbox fuzzing",
    "content": "The two types of fuzzing supported on ClusterFuzz are coverage guided fuzzing (using libFuzzer and AFL) and blackbox fuzzing. ",
    "url": "/clusterfuzz-document-cn/reference/coverage-guided-vs-blackbox/",
    "relUrl": "/reference/coverage-guided-vs-blackbox/"
  },"51": {
    "doc": "Coverage guided vs blackbox fuzzing",
    "title": "Coverage guided fuzzing",
    "content": "Coverage guided fuzzing (also known as greybox fuzzing) uses program instrumentation to trace the code coverage reached by each input fed to a fuzz target. Fuzzing engines use this information to make informed decisions about which inputs to mutate to maximize coverage. For every target, the fuzzing engine builds a corpus of inputs. These grow in coverage over time as the engine discovers new inputs through mutation. The fuzzing engines supported on ClusterFuzz are libFuzzer (recommended) and AFL. When should I use coverage guided fuzzing? . Coverage guided fuzzing is recommended as it is generally the most effective. This works best when: . | The target is self-contained. | The target is deterministic. | The target can execute dozens or more times per second (ideally hundreds or more). | . For example, binary format (e.g. image format) parsers are very well suited to this. ",
    "url": "/clusterfuzz-document-cn/reference/coverage-guided-vs-blackbox/#coverage-guided-fuzzing",
    "relUrl": "/reference/coverage-guided-vs-blackbox/#coverage-guided-fuzzing"
  },"52": {
    "doc": "Coverage guided vs blackbox fuzzing",
    "title": "Blackbox fuzzing",
    "content": "A blackbox fuzzer generates inputs for a target program without knowledge of its internal behaviour or implementation. A blackbox fuzzer may generate inputs from scratch, or rely on a static corpus of valid input files to base mutations on. Unlike coverage guided fuzzing, the corpus does not grow here. When should I use blackbox fuzzing? . Blackbox fuzzing works well when: . | The target is large. | The target is not deterministic for the same input. | The target is slow. | The input format is complicated or highly structured (e.g. a programming language such as JavaScript). | . For example, a browser DOM fuzzer may generate HTML inputs that are run against a target such as Chrome, without any coverage feedback to guide its mutations. ",
    "url": "/clusterfuzz-document-cn/reference/coverage-guided-vs-blackbox/#blackbox-fuzzing",
    "relUrl": "/reference/coverage-guided-vs-blackbox/#blackbox-fuzzing"
  },"53": {
    "doc": "Fixing a bug",
    "title": "Fixing a bug",
    "content": "Finding bugs is primarily useful if it can help get bugs fixed. To make fixing bugs easier, ClusterFuzz provides the necessary information to reproduce issues, and confirms that fixes are correct. This document focuses on the testcase details page, since it contains the majority of the relevant information for fixing a bug. | Fixing a bug . | Reproducing an issue | Fixed testing | Unreliable crashes | . | . ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/workflows/fixing-a-bug/",
    "relUrl": "/using-clusterfuzz/workflows/fixing-a-bug/"
  },"54": {
    "doc": "Fixing a bug",
    "title": "Reproducing an issue",
    "content": "The Overview section of the report contains links to download the testcase and build that triggered the issue. At the top of the crash stacktrace (which may need to be expanded), ClusterFuzz shows the command line and any important environment variables that were set when the crash initially occurred. The environment variables may be be required to reproduce the crash. ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/workflows/fixing-a-bug/#reproducing-an-issue",
    "relUrl": "/using-clusterfuzz/workflows/fixing-a-bug/#reproducing-an-issue"
  },"55": {
    "doc": "Fixing a bug",
    "title": "Fixed testing",
    "content": "Once a day, ClusterFuzz re-runs testcases against the latest build until it detects them as fixed. When an issue is detected as fixed, the Fixed status of the bug will be updated to “Yes” and the Fixed Revision Range section will link to a range of commits containing the fix. If the testcase has been associated with a bug, ClusterFuzz will also leave a comment and change the issue status to indicate that it has verified the fix is correct. ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/workflows/fixing-a-bug/#fixed-testing",
    "relUrl": "/using-clusterfuzz/workflows/fixing-a-bug/#fixed-testing"
  },"56": {
    "doc": "Fixing a bug",
    "title": "Unreliable crashes",
    "content": "ClusterFuzz does not consider testcases that do not reliably reproduce as important. However, if a crash state is seen very frequently despite not having a single reliable testcase for it, ClusterFuzz will file a bug for it. When ClusterFuzz finds a reliably reproducible testcase for the same crash state, it creates a new report and deletes the older report with the unreliable testcase. It is recommended in such cases to wait a few days to see if a reproducible testcase can be found. If not, you can try running the testcase multiple times to see if you can get a consistent crash locally. If that fails, we recommend pushing a speculative fix based on the crash stacktrace and then letting ClusterFuzz verify if the crash stops happening over the next couple of days. If a tracking bug is filed, ClusterFuzz will automatically look at crash statistics every day and close the bug as Verified if that crash stops happening frequently (i.e. no crash seen in a period of 2 weeks). If a bug is not filed, unreproducible testcases get automatically closed if they are not seen for a week. ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/workflows/fixing-a-bug/#unreliable-crashes",
    "relUrl": "/using-clusterfuzz/workflows/fixing-a-bug/#unreliable-crashes"
  },"57": {
    "doc": "Getting started",
    "title": "Getting started",
    "content": "以下页面会引导您完成本地设置ClusterFuzz以进行开发和测试的过程. ",
    "url": "/clusterfuzz-document-cn/getting-started/",
    "relUrl": "/getting-started/"
  },"58": {
    "doc": "Glossary",
    "title": "Glossary",
    "content": "本页面提供一份术语表, 描述各个术语在ClusterFuzz情境中的具体含义. | Glossary . | Bot | Corpus | Corpus pruning | Crash state | Crash type | Fuzz target | Fuzzer | Fuzzing engine | Job type | Minimization | Reliability of reproduction | Regression range | Revision | Sanitizer | Task | Testcase | . | . ",
    "url": "/clusterfuzz-document-cn/reference/glossary/",
    "relUrl": "/reference/glossary/"
  },"59": {
    "doc": "Glossary",
    "title": "Bot",
    "content": "一个运行ClusterFuzz任务的机器. ",
    "url": "/clusterfuzz-document-cn/reference/glossary/#bot",
    "relUrl": "/reference/glossary/#bot"
  },"60": {
    "doc": "Glossary",
    "title": "Corpus",
    "content": "Fuzz目标的一组输入. 在大多数情况下, 它指一组生成最大代码覆盖率的最小测试输入. ",
    "url": "/clusterfuzz-document-cn/reference/glossary/#corpus",
    "relUrl": "/reference/glossary/#corpus"
  },"61": {
    "doc": "Glossary",
    "title": "Corpus pruning",
    "content": "一项任务, 在保持相同代码覆盖率的同时, 选取一个语料库并除去不必要的输入. ",
    "url": "/clusterfuzz-document-cn/reference/glossary/#corpus-pruning",
    "relUrl": "/reference/glossary/#corpus-pruning"
  },"62": {
    "doc": "Glossary",
    "title": "Crash state",
    "content": "我们从崩溃堆栈跟踪记录里生成的一项用于删除重复数据的特征签名. ",
    "url": "/clusterfuzz-document-cn/reference/glossary/#crash-state",
    "relUrl": "/reference/glossary/#crash-state"
  },"63": {
    "doc": "Glossary",
    "title": "Crash type",
    "content": "崩溃的类型. ClusterFuzz使用崩溃类型来确认崩溃的严重程度. 对于安全漏洞, 类型可能是(但不限于)以下: . | Bad-cast | Heap-buffer-overflow | Heap-double-free | Heap-use-after-free | Stack-buffer-overflow | Stack-use-after-return | Use-after-poison | . 其他崩溃类型包括: . | Null-dereference | Timeout | Out-of-memory | Stack-overflow | ASSERT | . ",
    "url": "/clusterfuzz-document-cn/reference/glossary/#crash-type",
    "relUrl": "/reference/glossary/#crash-type"
  },"64": {
    "doc": "Glossary",
    "title": "Fuzz target",
    "content": "一个函数或程序, 接受一串字节数组并使用被测API对这些字节进行了某些研究人员感兴趣的操作. 有关更多详细说明请参见libFuzzer documentation. 通常由libFuzzer或AFL为Fuzz目标提供字节数组, 以进行覆盖率导向的模糊测试. ",
    "url": "/clusterfuzz-document-cn/reference/glossary/#fuzz-target",
    "relUrl": "/reference/glossary/#fuzz-target"
  },"65": {
    "doc": "Glossary",
    "title": "Fuzzer",
    "content": "一个能够为测试目标软件而生成/变异特定格式输入的程序. 例如, 它可能是一个通过生成有效的JavaScript测试用例来对JavaScript引擎(比如V8)进行模糊测试的程序. ",
    "url": "/clusterfuzz-document-cn/reference/glossary/#fuzzer",
    "relUrl": "/reference/glossary/#fuzzer"
  },"66": {
    "doc": "Glossary",
    "title": "Fuzzing engine",
    "content": "用于执行覆盖率导向的模糊测试的工具. 模糊测试引擎通常会根据新的覆盖率信息对输入进行变异, 获取覆盖率信息并将输入添加到语料库中去. ClusterFuzz目前支持的模糊测试引擎有libFuzzer和AFL. 有关配置libFuzzer和AFL的更多详细说明请参见我们的这篇教程. ",
    "url": "/clusterfuzz-document-cn/reference/glossary/#fuzzing-engine",
    "relUrl": "/reference/glossary/#fuzzing-engine"
  },"67": {
    "doc": "Glossary",
    "title": "Job type",
    "content": "有关如何运行特定目标程序进行模糊测试以及如何定位构建位置的规范, 由一系列环境变量值组成. ",
    "url": "/clusterfuzz-document-cn/reference/glossary/#job-type",
    "relUrl": "/reference/glossary/#job-type"
  },"68": {
    "doc": "Glossary",
    "title": "Minimization",
    "content": "一项试图将测试用例尺寸尽可能最小化的同时依然能在目标程序上触发相同错误的任务. ",
    "url": "/clusterfuzz-document-cn/reference/glossary/#minimization",
    "relUrl": "/reference/glossary/#minimization"
  },"69": {
    "doc": "Glossary",
    "title": "Reliability of reproduction",
    "content": "如果目标程序对于给定的输入始终以相同的崩溃状态崩溃, 则称为可靠地重现崩溃. ",
    "url": "/clusterfuzz-document-cn/reference/glossary/#reliability-of-reproduction",
    "relUrl": "/reference/glossary/#reliability-of-reproduction"
  },"70": {
    "doc": "Glossary",
    "title": "Regression range",
    "content": "最初引入该错误的一系列提交. 它的格式为x:y, 其中: . | x是起始修订版(含). | y是最终修订版(不包含). | . ",
    "url": "/clusterfuzz-document-cn/reference/glossary/#regression-range",
    "relUrl": "/reference/glossary/#regression-range"
  },"71": {
    "doc": "Glossary",
    "title": "Revision",
    "content": "一个可以用来标识特定构建的数字(不是git哈希). 每个源代码修订版该数值都会增加. 对于SVN该数值可能只是SVN源码修订版, 但对于Git, 您则需要创建一个数字到git哈希的等效映射. 映射编号可以是以1开头并递增的ID, 也可以是日期格式(例如20190110). ",
    "url": "/clusterfuzz-document-cn/reference/glossary/#revision",
    "relUrl": "/reference/glossary/#revision"
  },"72": {
    "doc": "Glossary",
    "title": "Sanitizer",
    "content": "一种动态测试工具, 使用编译时插装来检测程序运行期间的错误. 例如: . | ASan (aka AddressSanitizer) | LSan (aka LeakSanitizer) | MSan (aka MemorySanitizer) | UBSan (aka UndefinedBehaviorSanitizer) | TSan (aka ThreadSanitizer) | . Clang编译器对Sanitizers的支持最佳. ASan, 全称为AddressSanitizer, 通常是最重要的sanitizer, 因为它发现来最多的内存破坏错误. ",
    "url": "/clusterfuzz-document-cn/reference/glossary/#sanitizer",
    "relUrl": "/reference/glossary/#sanitizer"
  },"73": {
    "doc": "Glossary",
    "title": "Task",
    "content": "由bot执行的工作单元, 例如模糊测试会话或测试用例最小化. ",
    "url": "/clusterfuzz-document-cn/reference/glossary/#task",
    "relUrl": "/reference/glossary/#task"
  },"74": {
    "doc": "Glossary",
    "title": "Testcase",
    "content": "导致目标程序崩溃或错误的输入. 在测试用例详细信息页面上, 您可以下载”Minimized Testcase”或”Unminimized Testcase”, 这些指的均是需要传递给目标程序的输入. ",
    "url": "/clusterfuzz-document-cn/reference/glossary/#testcase",
    "relUrl": "/reference/glossary/#testcase"
  },"75": {
    "doc": "Heartbleed example",
    "title": "Finding Heartbleed",
    "content": "本教程将会向您展示如何使用libFuzzer和Clusterfuzz挖掘Heartbleed漏洞. | Finding Heartbleed . | Prerequisites | Building a libFuzzer target for OpenSSL | Uploading the fuzzer to ClusterFuzz | Fuzzing and seeing results | . | . ",
    "url": "/clusterfuzz-document-cn/setting-up-fuzzing/heartbleed-example/#finding-heartbleed",
    "relUrl": "/setting-up-fuzzing/heartbleed-example/#finding-heartbleed"
  },"76": {
    "doc": "Heartbleed example",
    "title": "Prerequisites",
    "content": "假设您现在正在使用一台Linux bot. 查阅位于libFuzzer和AFL++文档里的编译器段落, 获取以下示例的可用编译器, 并确保设置好了CC和CXX环境变量. ",
    "url": "/clusterfuzz-document-cn/setting-up-fuzzing/heartbleed-example/#prerequisites",
    "relUrl": "/setting-up-fuzzing/heartbleed-example/#prerequisites"
  },"77": {
    "doc": "Heartbleed example",
    "title": "Building a libFuzzer target for OpenSSL",
    "content": "运行以下命令构建一个用于OpenSSL的libFuzzer target. # 下载和解压一份受漏洞影响的OpenSSL版本代码 curl -O https://ftp.openssl.org/source/old/1.0.1/openssl-1.0.1f.tar.gz tar xf openssl-1.0.1f.tar.gz # 构建带有ASan和fuzzer插装的OpenSSL cd openssl-1.0.1f/ ./config # $CC必须指向clang二进制文件, 如何设置请查看上述\"编译器段落\"链接 make CC=\"$CC -g -fsanitize=address,fuzzer-no-link\" cd .. # 下载fuzz target及其依赖的数据. curl -O https://raw.githubusercontent.com/google/clusterfuzz/master/docs/setting-up-fuzzing/heartbleed/handshake-fuzzer.cc curl -O https://raw.githubusercontent.com/google/clusterfuzz/master/docs/setting-up-fuzzing/heartbleed/server.key curl -O https://raw.githubusercontent.com/google/clusterfuzz/master/docs/setting-up-fuzzing/heartbleed/server.pem # 构建用于ClusterFuzz的OpenSSL fuzz target ($CXX需要指向clang++二进制文件): $CXX -g handshake-fuzzer.cc -fsanitize=address,fuzzer openssl-1.0.1f/libssl.a \\ openssl-1.0.1f/libcrypto.a -std=c++17 -Iopenssl-1.0.1f/include/ -lstdc++fs \\ -ldl -lstdc++ -o handshake-fuzzer zip openssl-fuzzer-build.zip handshake-fuzzer server.key server.pem . ",
    "url": "/clusterfuzz-document-cn/setting-up-fuzzing/heartbleed-example/#building-a-libfuzzer-target-for-openssl",
    "relUrl": "/setting-up-fuzzing/heartbleed-example/#building-a-libfuzzer-target-for-openssl"
  },"78": {
    "doc": "Heartbleed example",
    "title": "Uploading the fuzzer to ClusterFuzz",
    "content": "首先我们需要创建一个任务: . | 导航至Jobs页面. | 来到”ADD NEW JOB”表单处. | 依照以下内容填充任务信息: . | 填写“libfuzzer_asan_linux_openssl” 至 “Name”. | 填写“LINUX” 至 “Platform”. | 填写“libFuzzer” 至 “Select/modify fuzzers”. | 填写“libfuzzer” 和 “engine_asan” 至 “Templates”. | 填写CORPUS_PRUNE = True 至 “Environment String”. | . | 选择 openssl-fuzzer-build.zip并上传为”Custom Build”. | 使用”ADD”按钮将该Job添加至ClusterFuzz. | . ",
    "url": "/clusterfuzz-document-cn/setting-up-fuzzing/heartbleed-example/#uploading-the-fuzzer-to-clusterfuzz",
    "relUrl": "/setting-up-fuzzing/heartbleed-example/#uploading-the-fuzzer-to-clusterfuzz"
  },"79": {
    "doc": "Heartbleed example",
    "title": "Fuzzing and seeing results",
    "content": "如果您遵照local ClusterFuzz教程配置好了本地的server和bot实例, 并且同时也没有其他任何fuzzing任务正在运行, 那么您接下来应该就能在bot logs处看到fuzz libFuzzer libfuzzer_asan_linux_openssl的字样. 这代表着ClusterFuzz正在对您构建的代码进行模糊测试. 不久后您就能在日志里看到崩溃栈信息以及字符串AddressSanitizer: heap-buffer-overflow. 如果您遵照的是教程production instance of ClusterFuzz, 那么您可以在Bots页面看到fuzz libFuzzer libfuzzer_asan_linux_openssl字样. 具体花费的时间取决于您可能承担的其他工作负荷. 随后, 您可以转到ClusterFuzz首页(或者Testcases页面), 您将会看到一个标题名为“Heap-buffer-overflow READ{*}”的测试用例. 这就是由ClusterFuzz发现的心脏滴血漏洞. ",
    "url": "/clusterfuzz-document-cn/setting-up-fuzzing/heartbleed-example/#fuzzing-and-seeing-results",
    "relUrl": "/setting-up-fuzzing/heartbleed-example/#fuzzing-and-seeing-results"
  },"80": {
    "doc": "Heartbleed example",
    "title": "Heartbleed example",
    "content": " ",
    "url": "/clusterfuzz-document-cn/setting-up-fuzzing/heartbleed-example/",
    "relUrl": "/setting-up-fuzzing/heartbleed-example/"
  },"81": {
    "doc": "ClusterFuzz",
    "title": "ClusterFuzz",
    "content": ". ClusterFuzz是一个可扩展的用于发现软件中安全性和稳定性问题的模糊测试基础设施. Google使用ClusterFuzz对所有的Google产品进行模糊测试, 并且作为模糊测试后端为OSS-Fuzz提供支持. ClusterFuzz提供了许多功能, 并且能将模糊测试功能无缝地集成到软件项目的开发过程中： . | 高可扩展性. 可以在任何大小的群集上运行(例如Google运行了约30,000个虚拟机实例). | 准确地对产生的崩溃进行去重. | 支持使用各种问题跟踪工具(例如Monorail, Jira）自动地对错误进归档, 分类和关闭. | 支持使用多种覆盖率导向的模糊测试引擎(libFuzzer, AFL++和Honggfuzz)以获得最佳结果.(结合Ensemble模糊测试和模糊测试策略). | 支持黑盒模糊测试. | 测试用例最小化. | 通过二分选择进行回归查找. | 提供了分析Fuzzer性能和崩溃率的统计信息. | 易于使用的Web界面, 用于管理和查看崩溃信息. | 基于Firebase可支持各种身份验证提供程序. | . ",
    "url": "/clusterfuzz-document-cn/",
    "relUrl": "/"
  },"82": {
    "doc": "ClusterFuzz",
    "title": "Trophies",
    "content": "截至2020年9月, ClusterFuzz为Google发现了25,000多个错误(例如Chrome), 并在超过340个集成到OSS-Fuzz的开源项目中发现了~22,500个错误. ",
    "url": "/clusterfuzz-document-cn/#trophies",
    "relUrl": "/#trophies"
  },"83": {
    "doc": "Job definition",
    "title": "Job definition",
    "content": "This page walks you through various options that can be used for configuring a ClusterFuzz job. You may not need to use many of these options. | Job definition . | Environment variables . | Common variables | LibFuzzer and AFL specific | Blackbox fuzzing specific | . | Examples . | LibFuzzer and AFL | Blackbox fuzzing | . | . | . ",
    "url": "/clusterfuzz-document-cn/reference/job-definition/",
    "relUrl": "/reference/job-definition/"
  },"84": {
    "doc": "Job definition",
    "title": "Environment variables",
    "content": "Jobs can be created or edited on the Jobs page. A job definition mostly consists of environment variables. If you use a job template when configuring a job, the template will add the variables that are specified in the job template definition. Common variables . | CUSTOM_BINARY: indicates whether a job uses a manually uploaded build or not. Use CUSTOM_BINARY = True if you upload a build when creating a job. If you use RELEASE_BUILD_BUCKET_PATH to specify a build stored in a Google Cloud Storage bucket, use CUSTOM_BINARY = False. | RELEASE_BUILD_BUCKET_PATH: indicates a path to the build that is uploaded to Google Cloud Storage bucket. See specifying a continuous build for more detail. | ADDITIONAL_ASAN_OPTIONS: provides a way to specify custom runtime flags for AddressSanitizer. The values specified here will overwrite the default values used by ClusterFuzz. The same type of variable is available for the other sanitizers, i.e. ADDITIONAL_MSAN_OPTIONS or ADDITIONAL_UBSAN_OPTIONS (see an example below on this page). | . LibFuzzer and AFL specific . | CORPUS_PRUNE: indicates whether a corpus pruning needs to be done using a given job. The default value is False. It’s recommended to use CORPUS_PRUNE = True for libFuzzer ASan jobs only. Enabling pruning for a one job only is sufficient, as other libFuzzer and AFL jobs use the same corpus when running the same fuzz targets. | . Blackbox fuzzing specific . | APP_NAME: indicates the file name of a target application to be tested. | APP_ARGS: arguments to be passed to the target application. This variable should include both optional and required arguments you want to pass. | REQUIRED_APP_ARGS: arguments that must be passed to the target application. These arguments will be always used, while the others specified in APP_ARGS and not specified here can be removed by ClusterFuzz during testcase minimization if they aren’t needed to reproduce a crash. | TEST_TIMEOUT: indicates how many seconds a target application can spend on processing an individual testcase. | . ",
    "url": "/clusterfuzz-document-cn/reference/job-definition/#environment-variables",
    "relUrl": "/reference/job-definition/#environment-variables"
  },"85": {
    "doc": "Job definition",
    "title": "Examples",
    "content": "Below are some examples of job definitions used on a production instance of ClusterFuzz. LibFuzzer and AFL . Job name: libfuzzer_asan_zlib . Platform: LINUX . Templates: . libfuzzer engine_asan . Environment String: . RELEASE_BUILD_BUCKET_PATH = gs://clusterfuzz-builds/zlib/zlib-address-([0-9]+).zip CUSTOM_BINARY = False CORPUS_PRUNE = True . Job name: libfuzzer_ubsan_zlib . Platform: LINUX . Templates: . libfuzzer engine_ubsan . Environment String: . RELEASE_BUILD_BUCKET_PATH = gs://clusterfuzz-builds/zlib/zlib-undefined-([0-9]+).zip CUSTOM_BINARY = False . Job name: afl_asan_zlib . Platform: LINUX . Templates: . afl engine_asan . Environment String: . RELEASE_BUILD_BUCKET_PATH = gs://clusterfuzz-builds-afl/zlib/zlib-address-([0-9]+).zip CUSTOM_BINARY = False . Blackbox fuzzing . Job name: asan_linux_chrome . Platform: LINUX . Templates: none . Environment String: . RELEASE_BUILD_BUCKET_PATH = gs://chromium-browser-asan/linux-release/asan-linux-release-([0-9]+).zip MIN_REVISION = 441045 CUSTOM_BINARY = False APP_NAME = chrome APP_ARGS = --enable-experimental-extension-apis --enable-extension-apps --js-flags=\"--expose-gc --verify-heap\" --no-first-run --use-gl=swiftshader --disable-in-process-stack-traces REQUIRED_APP_ARGS = --no-first-run --use-gl=swiftshader --disable-in-process-stack-traces TEST_TIMEOUT = 15 ADDITIONAL_ASAN_OPTIONS = allocator_may_return_null=0 . ",
    "url": "/clusterfuzz-document-cn/reference/job-definition/#examples",
    "relUrl": "/reference/job-definition/#examples"
  },"86": {
    "doc": "libFuzzer and AFL++",
    "title": "libFuzzer and AFL",
    "content": "This page walks you through setting up coverage guided fuzzing using libFuzzer or [AFL]. It also serves as a reference for using more advanced features such as dictionaries and seed corpus. 本页面将引导您设置好覆盖率导向模糊测试环境(使用libFuzzeror[AFL]). | libFuzzer and AFL . | Prerequisites . | Compiler | Platform | . | Builds . | libFuzzer | AFL | . | Creating a job type . | Enabling corpus pruning | . | Checking results | Seed corpus | Dictionaries | AFL limitations | . | . ",
    "url": "/clusterfuzz-document-cn/setting-up-fuzzing/libfuzzer-and-afl/#libfuzzer-and-afl",
    "relUrl": "/setting-up-fuzzing/libfuzzer-and-afl/#libfuzzer-and-afl"
  },"87": {
    "doc": "libFuzzer and AFL++",
    "title": "Prerequisites",
    "content": "Compiler . LibFuzzer and AFL need to use instrumentation from the Clang compiler. In our documentation, we use features provided by Clang 6.0 or greater. However, for serious use of ClusterFuzz, we recommend using as close to trunk Clang as possible. To get a Clang build that is close to trunk you can download it from the snapshots page (Windows) or follow the instructions on the apt page (Ubuntu/Debian). Otherwise you can download a Clang release from the releases page or install one using your package manager. We will refer to these compilers in examples as $CC and $CXX. Set these in the environment so that you can copy and paste the example commands: . export CC=/path/to/clang export CXX=/path/to/clang++ . Platform . libFuzzer is supported on Linux, macOS, and Windows. For Windows, you will need to change the commands to work in cmd.exe and you will need Clang 9.0 or greater which you can download from the LLVM Snapshot Builds page. AFL is only supported on Linux. AFL仅支持在Linux平台上运行. ",
    "url": "/clusterfuzz-document-cn/setting-up-fuzzing/libfuzzer-and-afl/#prerequisites",
    "relUrl": "/setting-up-fuzzing/libfuzzer-and-afl/#prerequisites"
  },"88": {
    "doc": "libFuzzer and AFL++",
    "title": "Builds",
    "content": "libFuzzer . LibFuzzer targets are easy to build. Just compile and link a fuzz target with -fsanitize=fuzzer and a sanitizer such as AddressSanitizer (-fsanitize=address). LibFuzzer的构建过程十分简单. 只需进行编译并跟两个目标链接即可. 一个是使用选项-fsanitize=fuzzer链接一个fuzz target, 另一个是使用选项-fsanitize=address链接一个sanitizer, 比如AddressSanitizer. $CXX -fsanitize=address,fuzzer fuzzer.cc -o fuzzer # Test out the build by fuzzing it./fuzzer -runs=10 # Create a fuzzer build to upload to ClusterFuzz. zip fuzzer-build.zip fuzzer . libFuzzer builds are zip files that contain any targets you want to fuzz and their dependencies. AFL . ClusterFuzz supports fuzzing libFuzzer harness functions (LLVMFuzzerTestOneInput) with AFL++. AFL++ must be used with AddressSanitizer. To build a fuzz target for AFL, run our script which downloads and builds AFL and FuzzingEngine.a, a library you can link the target against to make it AFL compatible. Then compile and link your target using -fsanitize-coverage=trace-pc-guard and -fsanitize=address. Note: This will not use AFL++ to it’s full potential as advanced fuzzing features like CMPLOG and COMPCOV will not be enabled. It is therefore recommended to use oss-fuzz to create (multiple) fuzzing packages instead, as each package is instrumented with random options. # Build afl-fuzz and FuzzingEngine.a ./build_afl.bash # Compile target using ASan, coverage instrumentation, and link against FuzzingEngine.a $CXX -fsanitize=address -fsanitize-coverage=trace-pc-guard fuzzer.cc FuzzingEngine.a -o fuzzer # Test out the build by fuzzing it. INPUT_CORPUS is a directory containing files. Ctrl-C when done. AFL_SKIP_CPUFREQ=1 ./afl-fuzz -i $INPUT_CORPUS -o output -m none ./fuzzer # Create a fuzzer build to upload to ClusterFuzz. zip fuzzer-build.zip fuzzer afl-fuzz afl-showmap . AFL builds are zip files that contain any targets you want to fuzz, their dependencies, and AFL’s dependencies: afl-fuzz and afl-showmap (both built by the script). ",
    "url": "/clusterfuzz-document-cn/setting-up-fuzzing/libfuzzer-and-afl/#builds",
    "relUrl": "/setting-up-fuzzing/libfuzzer-and-afl/#builds"
  },"89": {
    "doc": "libFuzzer and AFL++",
    "title": "Creating a job type",
    "content": "LibFuzzer jobs must contain the string “libfuzzer” in their name, AFL++ jobs must contain the string “afl” in their name. Jobs must also contain the name of the sanitizer they are using (e.g. “asan”, “msan”, or “ubsan”). “libfuzzer_asan_my_project” and “afl_asan_my_project” are examples of correct names for libFuzzer and AFL jobs that use AddressSanitizer. To create a job for libFuzzer or AFL: . | Navigate to the Jobs page. | Go to the “ADD NEW JOB” form. | Fill out the “Name” and “Platform” (LINUX). | Enable the desired fuzzer in the “Select/modify fuzzers” field, e.g. libFuzzer, honggfuzz, or afl. | If setting up an AFL job, use the templates “afl” and “engine_asan”. | If setting up a honggfuzz job, use the templates “honggfuzz” and “engine_asan”. | If setting up a libFuzzer job, use the templates “libfuzzer” and “engine_$SANITIZER” depending on which sanitizer you are using (e.g. “engine_asan”). | Select your build (your zip containing the fuzz target binary) to upload as a “Custom Build”. If you are running ClusterFuzz in production, it is recommended to set up a build pipeline and follow these instructions on providing continuous builds rather than using a “Custom Build”. | Use the “ADD” button to add the job to ClusterFuzz. | . Enabling corpus pruning . It is important that you enable corpus pruning to run once a day to prevent uncontrolled corpus growth. This must be done by setting CORPUS_PRUNE = True in the “Environment String” for your libFuzzer ASan job. ",
    "url": "/clusterfuzz-document-cn/setting-up-fuzzing/libfuzzer-and-afl/#creating-a-job-type",
    "relUrl": "/setting-up-fuzzing/libfuzzer-and-afl/#creating-a-job-type"
  },"90": {
    "doc": "libFuzzer and AFL++",
    "title": "Checking results",
    "content": "You can observe ClusterFuzz fuzzing your build by looking at the bot logs. Any bugs it finds can be found on the Testcases page. If you are running ClusterFuzz in production (ie: not locally), you can also view crash stats and fuzzer stats (one generally needs to wait a day to view fuzzer stats). ",
    "url": "/clusterfuzz-document-cn/setting-up-fuzzing/libfuzzer-and-afl/#checking-results",
    "relUrl": "/setting-up-fuzzing/libfuzzer-and-afl/#checking-results"
  },"91": {
    "doc": "libFuzzer and AFL++",
    "title": "Seed corpus",
    "content": "You can optionally upload a zip file in your build containing sample inputs for ClusterFuzz to give to your fuzzer. We call this a seed corpus. For a given fuzz target, ClusterFuzz will use a file as a seed corpus if: . | It is in the same directory in the build as the fuzz target. | It has the same name as the fuzz target (not including .exe extension) followed by _seed_corpus.zip (i.e. &lt;fuzz_target&gt;_seed_corpus.zip for &lt;fuzz_target&gt;). | . We recommend zipping directories of interesting inputs at build time to create a seed corpus. ",
    "url": "/clusterfuzz-document-cn/setting-up-fuzzing/libfuzzer-and-afl/#seed-corpus",
    "relUrl": "/setting-up-fuzzing/libfuzzer-and-afl/#seed-corpus"
  },"92": {
    "doc": "libFuzzer and AFL++",
    "title": "Dictionaries",
    "content": "ClusterFuzz supports using libFuzzer/AFL Dictionaries. A dictionary is a list of tokens that AFL or libFuzzer can insert during fuzzing. For a given fuzz target, ClusterFuzz will use a file as a dictionary if: . | It is in the same directory in the build as the fuzz target. | It has the same name as the fuzz target (not including .exe extension) followed by .dict (i.e. &lt;fuzz_target&gt;.dict for &lt;fuzz_target&gt;). | . ",
    "url": "/clusterfuzz-document-cn/setting-up-fuzzing/libfuzzer-and-afl/#dictionaries",
    "relUrl": "/setting-up-fuzzing/libfuzzer-and-afl/#dictionaries"
  },"93": {
    "doc": "libFuzzer and AFL++",
    "title": "AFL limitations",
    "content": "Though ClusterFuzz supports fuzzing with AFL, it doesn’t support using it for corpus pruning and crash minimization. Therefore, if you use AFL, you should also use libFuzzer which supports these tasks. ",
    "url": "/clusterfuzz-document-cn/setting-up-fuzzing/libfuzzer-and-afl/#afl-limitations",
    "relUrl": "/setting-up-fuzzing/libfuzzer-and-afl/#afl-limitations"
  },"94": {
    "doc": "libFuzzer and AFL++",
    "title": "libFuzzer and AFL++",
    "content": " ",
    "url": "/clusterfuzz-document-cn/setting-up-fuzzing/libfuzzer-and-afl/",
    "relUrl": "/setting-up-fuzzing/libfuzzer-and-afl/"
  },"95": {
    "doc": "Running a local instance",
    "title": "Local instance of ClusterFuzz",
    "content": "您可以运行ClusterFuzz的本地实例来测试核心功能. 请注意, 由于缺少Google Cloud模拟器, 某些功能(例如崩溃和模糊器统计信息)在本地实例中被禁用. | Running a local server | Running a local bot instance . | Viewing logs | . | Local Google Cloud Storage | . ",
    "url": "/clusterfuzz-document-cn/getting-started/local-instance/#local-instance-of-clusterfuzz",
    "relUrl": "/getting-started/local-instance/#local-instance-of-clusterfuzz"
  },"96": {
    "doc": "Running a local instance",
    "title": "Running a local server",
    "content": "您可以通过运行以下命令来启动一个本地服务器: . # 如果您是第一次运行该服务器或则想要重置所有的数据. python butler.py run_server --bootstrap # 在所有其他的情形下, 请勿使用\"--bootstrap\"标志. python butler.py run_server . 一开始可能需要花费几秒钟启动. 一旦您看到类似[INFO] Listening at: http://0.0.0.0:9000的输出信息时, 您就可以通过导航到http://localhost:9000查看网页界面. 注意: 本地实例可以使用9000以外的其他端口(例如9008)来进行文件上传等操作. 如果所需的端口不可用, 或者您只能从浏览器访问某些所需的端口(例如, 从另一台主机访问时具有端口转发或防火墙规则), 则您的本地实例可能会被中断. ",
    "url": "/clusterfuzz-document-cn/getting-started/local-instance/#running-a-local-server",
    "relUrl": "/getting-started/local-instance/#running-a-local-server"
  },"97": {
    "doc": "Running a local instance",
    "title": "Running a local bot instance",
    "content": "您可以通过运行以下命令在本地实例中运行ClusterFuzz机器人: . python butler.py run_bot --name my-bot /path/to/my-bot # 将my-bot命名成其他名称 . 该命令会在/path/to/my-bot/clusterfuzz下创建ClusterFuzz的代码副本, 并使用它来运行bot. 大多数机器人组件(例如日志，模糊器和语料库)都在bot子目录中创建. 如果您打算对原生GUI应用程序进行模糊测试, 建议您在虚拟帧缓冲区(如Xvfb)中运行此命令. 否则, 您将在模糊测试过程中看到GUI对话框. Viewing logs . 您可以通过运行以下命令查看本地实例上的日志: . cd /path/to/my-bot/clusterfuzz/bot/logs tail -f bot.log . 注意: 在您有设置任何模糊测试任务之前, 您会在 日志中看到无害的错误提示: Failed to get any fuzzing tasks. ",
    "url": "/clusterfuzz-document-cn/getting-started/local-instance/#running-a-local-bot-instance",
    "relUrl": "/getting-started/local-instance/#running-a-local-bot-instance"
  },"98": {
    "doc": "Running a local instance",
    "title": "Local Google Cloud Storage",
    "content": "我们使用了本地的文件系统对Google Cloud Storage进行了模拟. 默认情况下, 它存储在ClusterFuzz项目路径local/storage/local_gcs处. 您可以通过执行以下操作覆盖默认位置: . | 运行run_server命令时使用--storage-path标志. | 运行run_bot命令时使用--server-storage-path标志来指定相同路径. | . 在您指定的位置, 对象存储在&lt;bucket&gt;/objects/&lt;object path&gt;处, 元数据存储在&lt;bucket&gt;/metadata/&lt;object path&gt;处. ",
    "url": "/clusterfuzz-document-cn/getting-started/local-instance/#local-google-cloud-storage",
    "relUrl": "/getting-started/local-instance/#local-google-cloud-storage"
  },"99": {
    "doc": "Running a local instance",
    "title": "Running a local instance",
    "content": " ",
    "url": "/clusterfuzz-document-cn/getting-started/local-instance/",
    "relUrl": "/getting-started/local-instance/"
  },"100": {
    "doc": "Prerequisites",
    "title": "Prerequisites",
    "content": "本页面说明了如何设置环境使用ClusterFuzz. | Requirements | Getting the code | Installing prerequisites . | Google Cloud SDK | Log in to your Google Cloud account | Python programming language | Go programming language | Other dependencies | . | Loading pipenv | . ",
    "url": "/clusterfuzz-document-cn/getting-started/prerequisites/",
    "relUrl": "/getting-started/prerequisites/"
  },"101": {
    "doc": "Prerequisites",
    "title": "Requirements",
    "content": "ClusterFuzz的许多功能依赖于Google Cloud Platform 服务, 但它同样可以无须这些依赖在本地运行起来作为测试用途. 更多细节请查阅Architecture page了解. 注意: 本地开发环境仅支持Linux平台. ",
    "url": "/clusterfuzz-document-cn/getting-started/prerequisites/#requirements",
    "relUrl": "/getting-started/prerequisites/#requirements"
  },"102": {
    "doc": "Prerequisites",
    "title": "Getting the code",
    "content": "运行以下命令克隆ClusterFuzz到你的计算机上: . git clone https://github.com/google/clusterfuzz cd clusterfuzz git pull . 出于稳定性考虑, 我们建议您使用代码的最新发行版本(而非master分支). 您可以使用以下命令切换到特定版本: . git checkout tags/vX.Y.Z . 其中 X.Y.Z 是具体到发布版本(比如, 1.0.1). ",
    "url": "/clusterfuzz-document-cn/getting-started/prerequisites/#getting-the-code",
    "relUrl": "/getting-started/prerequisites/#getting-the-code"
  },"103": {
    "doc": "Prerequisites",
    "title": "Installing prerequisites",
    "content": "Google Cloud SDK . 遵循在线说明安装Google Cloud SDK. Log in to your Google Cloud account . 注意: 如果您在本地运行ClusterFuzz, 那么这部分内容不是”必需”的. 如果您打算在生产环境中设置ClusterFuzz, 则应使用gcloud工具对您的帐户进行身份验证: . gcloud auth application-default login gcloud auth login . Python programming language . 下载 Python 3.7并安装. 如果已经安装好了Python, 则可以通过运行python --version来验证版本. 我们建议使用官方仓库中的python源码进行构建, 因为它会安装所需的python头文件和pip. 否则, 请确保明确安装了它们. Go programming language . Install the Go programming language. Other dependencies . 我们提供了一个脚本, 用于在Linux和macOS上安装所有其他的开发依赖项. 我们支持的系统包括有: . | Ubuntu (14.04, 16.04, 17.10, 18.04, 18.10) | Debian 8 (jessie) 或更高版本 | 安装有homebrew的macOS最新版本(实验性) | . 要安装依赖项, 请运行以下脚本: . local/install_deps.bash . ",
    "url": "/clusterfuzz-document-cn/getting-started/prerequisites/#installing-prerequisites",
    "relUrl": "/getting-started/prerequisites/#installing-prerequisites"
  },"104": {
    "doc": "Prerequisites",
    "title": "Loading pipenv",
    "content": "在运行完local/install_deps.bash脚本之后, 通过运行以下命令激活pipenv: . pipenv shell . 该命令会载入所有到Python依赖到当前到环境中去. 您可以运行以下命令验证环境是否配置成功. python butler.py --help . ",
    "url": "/clusterfuzz-document-cn/getting-started/prerequisites/#loading-pipenv",
    "relUrl": "/getting-started/prerequisites/#loading-pipenv"
  },"105": {
    "doc": "Production setup",
    "title": "Production setup",
    "content": "这些页面将引导您搭建用于生产的ClusterFuzz, 并启用所有的功能. ",
    "url": "/clusterfuzz-document-cn/production-setup/",
    "relUrl": "/production-setup/"
  },"106": {
    "doc": "Reference",
    "title": "Reference",
    "content": " ",
    "url": "/clusterfuzz-document-cn/reference/",
    "relUrl": "/reference/"
  },"107": {
    "doc": "Running unit tests",
    "title": "Running unit tests",
    "content": ". | Running unit tests . | Test core changes . | Python code | . | Test App Engine changes | . | . ",
    "url": "/clusterfuzz-document-cn/contributing-code/running-unit-tests/",
    "relUrl": "/contributing-code/running-unit-tests/"
  },"108": {
    "doc": "Running unit tests",
    "title": "Test core changes",
    "content": "您可以使用以下命令运行针对核心功能的单元测试: . Python code . python butler.py py_unittest -t core . 可以使用的可选开关: . | -m: 并行地执行测试(推荐). | -v: 以详细模式(INFO日志级别)运行测试. | -u: 显示print的输出(利于调试). | -p &lt;test_name/test_prefix_with_wildcards&gt;: 执行一个特定的测试或一组与特定前缀匹配的测试. 例如:-p libfuzzer_ *将执行所有以libFuzzer为前缀命名的单元测试. | . ",
    "url": "/clusterfuzz-document-cn/contributing-code/running-unit-tests/#test-core-changes",
    "relUrl": "/contributing-code/running-unit-tests/#test-core-changes"
  },"109": {
    "doc": "Running unit tests",
    "title": "Test App Engine changes",
    "content": "大多数App Engine代码都是用Python编写的. 您可以使用以下命令对App Engine的改动(例如UI,cron)运行单元测试. python butler.py py_unittest -t appengine . 您同样可以使用上述在Python code段中定义的任何开关. ",
    "url": "/clusterfuzz-document-cn/contributing-code/running-unit-tests/#test-app-engine-changes",
    "relUrl": "/contributing-code/running-unit-tests/#test-app-engine-changes"
  },"110": {
    "doc": "Setting up a fuzzing job",
    "title": "Setting up a fuzzing job",
    "content": "This page walks you through setting up a fuzzing job in production. That process repeats the steps described in setting up fuzzing, but also requires extra configuration for automated build updates. | Setting up a fuzzing job . | Prerequisites | Creating a job definition | Specifying a continuous build | Advanced options . | Ignoring outdated revisions | Linking to documentation | Job definition reference | . | . | . ",
    "url": "/clusterfuzz-document-cn/production-setup/setting-up-fuzzing-job/",
    "relUrl": "/production-setup/setting-up-fuzzing-job/"
  },"111": {
    "doc": "Setting up a fuzzing job",
    "title": "Prerequisites",
    "content": "To take full advantage of continuous fuzzing, you should set up a build pipeline first. By doing this, ClusterFuzz will automatically find bugs in your most recent changes, report ranges of commits where regressions are introduced, and verify fixes. If you wish to run with a single build while preparing a build pipeline, you can follow the setting up fuzzing instructions directly. ",
    "url": "/clusterfuzz-document-cn/production-setup/setting-up-fuzzing-job/#prerequisites",
    "relUrl": "/production-setup/setting-up-fuzzing-job/#prerequisites"
  },"112": {
    "doc": "Setting up a fuzzing job",
    "title": "Creating a job definition",
    "content": "You can create a job definition on the Jobs page. To understand the process of job creation, see setting up fuzzing. That page explains the difference between two fuzzing approaches (coverage guided vs blackbox) and provides guidance on how to set up a job for each of those. ",
    "url": "/clusterfuzz-document-cn/production-setup/setting-up-fuzzing-job/#creating-a-job-definition",
    "relUrl": "/production-setup/setting-up-fuzzing-job/#creating-a-job-definition"
  },"113": {
    "doc": "Setting up a fuzzing job",
    "title": "Specifying a continuous build",
    "content": "To allow ClusterFuzz to take advantage of your build pipeline you must point to the Google Cloud Storage bucket where your builds are stored in your job definition’s “Environment String”. RELEASE_BUILD_BUCKET_PATH = gs://my-bucket/my-build-([0-9]+).zip CUSTOM_BINARY = False # These are only needed for blackbox fuzzing. APP_NAME = myapp APP_ARGS = -args -to -pass -to -myapp ... The RELEASE_BUILD_BUCKET_PATH in the above example is a regular expression that specifies which bucket to read build archives from. Any files in the bucket that match the specified expression are treated as potential builds for this job. In this example, a build at the path gs://my-bucket/my-build-123.zip would be a match, and would be used by this job. The ([0-9]+) regex in RELEASE_BUILD_BUCKET_PATH is used to compute the revision number for this build. This is used to determine which builds are newer than others. The build with the highest revision number will always be selected for fuzzing. ClusterFuzz expects that any build with a greater revision number than another is the newer build. Note: The parentheses around the revision number regex are required and is the match group that ClusterFuzz uses to determine which part of the expression represents the revision number. For a complete list of options, look at bot/env.yaml in the source checkout. ",
    "url": "/clusterfuzz-document-cn/production-setup/setting-up-fuzzing-job/#specifying-a-continuous-build",
    "relUrl": "/production-setup/setting-up-fuzzing-job/#specifying-a-continuous-build"
  },"114": {
    "doc": "Setting up a fuzzing job",
    "title": "Advanced options",
    "content": "Ignoring outdated revisions . In addition to the variables defined above, you may also define the MIN_REVISION variable. This can be useful when you make significant, non-backwards-compatible changes in your build such that older revisions will not work properly and need to be discarded. Linking to documentation . A job can specify a HELP_URL which each test case report for this job will link to. This allows you to provide instructions to developers on how they should treat the bugs they are assigned. Job definition reference . For a more comprehensive overview of the options, see the job definition reference page. ",
    "url": "/clusterfuzz-document-cn/production-setup/setting-up-fuzzing-job/#advanced-options",
    "relUrl": "/production-setup/setting-up-fuzzing-job/#advanced-options"
  },"115": {
    "doc": "Setting up bots",
    "title": "Setting up bots",
    "content": "This page walks you through the process of setting up bots on each of the supported platforms: Linux, Windows and macOS. | Setting up bots . | Platforms . | Linux | Windows | macOS | . | Configuration . | Google Compute Engine Cluster | Google Compute Engine Instance Template | Windows password setup | Deploying new changes | . | Verification . | Google Compute Engine bots | Non-Google Compute Engine bots | . | . | . ",
    "url": "/clusterfuzz-document-cn/production-setup/setting-up-bots/",
    "relUrl": "/production-setup/setting-up-bots/"
  },"116": {
    "doc": "Setting up bots",
    "title": "Platforms",
    "content": "Linux . Linux is the preferred platform for fuzzing because of its comprehensive support for all sanitizer and fuzzing engine types. It is recommended to use each sanitizer its own build and job definition (except LeakSanitizer), as there are performance and bug finding efficiency issues with combining them. By default, the ClusterFuzz configuration file creates 1 regular Linux bot and 2 preemptible Linux bots on Google Compute Engine. You can configure them by following the instructions provided here and here. We recommend that you use preemptibles for most of your bots because they are much cheaper and perform almost as well. You still need some regular bots (non-preemptibles) to execute other tasks, such as the tasks that run after a crash is discovered (minimization, regression, etc). Windows . Windows is a supported platform for fuzzing. The only sanitizer supported on Windows is AddressSanitizer. The only fuzzing engine supported on Windows is libFuzzer. By default, ClusterFuzz configuration files do not enable any Windows bots. You can enable them easily by following the instructions provided here and here. You also need to set a password for the administrator account on the bots. macOS . Mac is a supported platform for fuzzing. The sanitizers supported on Mac are AddressSanitizer, LeakSanitizer, UndefinedBehaviorSanitizer and ThreadSanitizer. The only fuzzing engine supported on Mac is libFuzzer. Mac is not a supported platform on Google Compute Engine, so you would need to run it on physical hardware or some sort of virtualization running on top of it. Below are the steps to set up and run ClusterFuzz: . | Create a service account key following the instructions provided here. | Choose “Compute Engine” service account type. | Choose “JSON” key type. | . | Securely transfer the downloaded key file to the macOS computer. | Run the provided startup script. | . export CLOUD_PROJECT_ID=&lt;your project id&gt; export CONFIG_DIR=/path/to/myconfig export GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account-key.json export INSTALL_DIRECTORY=/path/where/to/install/clusterfuzz-and-dependencies/to $CONFIG_DIR/bot/setup/mac.bash . ",
    "url": "/clusterfuzz-document-cn/production-setup/setting-up-bots/#platforms",
    "relUrl": "/production-setup/setting-up-bots/#platforms"
  },"117": {
    "doc": "Setting up bots",
    "title": "Configuration",
    "content": "Google Compute Engine Cluster . You can configure a cluster of bots on Google Compute Engine by modifying the configuration file $CONFIG_DIR/gce/clusters.yaml. The clusters definition is in the &lt;your project id&gt;/clusters attribute of this yaml file. Below are example definitions for preemptible and regular Linux bots: . # Regular bots run all task types (e.g fuzzing, minimize, etc). clusterfuzz-linux: gce_zone: gce-zone instance_count: 1 instance_template: clusterfuzz-linux distribute: False # Pre-emptible bots must have '-pre-' in name. They only run fuzzing tasks. clusterfuzz-linux-pre: gce_zone: gce-zone instance_count: 2 instance_template: clusterfuzz-linux-pre distribute: False . You can configure the bots by first uncommenting the cluster definition, and then changing the values in the gce_zone (e.g. us-central1-a) and instance_count attributes. You can also create your own instance template and then define a new cluster section here. Note: . | Make sure to deploy new changes. Otherwise, they will not be reflected in production. | . Google Compute Engine Instance Template . You can read more about instance templates here. Instance templates define the properties of a bot (e.g. source image, disk space, network config). They are defined after the clusters configuration section in $CONFIG_DIR/gce/clusters.yaml. Below is an example for a regular Linux bot: . instance_templates: - name: clusterfuzz-linux description: '{\"version\": 1}' properties: machineType: n1-standard-1 disks: - boot: true autoDelete: true initializeParams: sourceImage: projects/cos-cloud/global/images/family/cos-stable diskSizeGb: 100 diskType: pd-standard metadata: items: - key: docker-image value: gcr.io/clusterfuzz-images/base:c44bf3f-201902112042 - key: user-data value: file://linux-init.yaml serviceAccounts: - email: my-project-id-service-account-email scopes: - https://www.googleapis.com/auth/cloud-platform - https://www.googleapis.com/auth/prodxmon networkInterfaces: - network: global/networks/default accessConfigs: - type: ONE_TO_ONE_NAT name: 'External NAT' . For example, you can configure the size of the disk using diskSizeGb attribute. Note: . | After making a change in the instance template, you must increment the version by 1. | Make sure to deploy new changes. Otherwise, they will not be reflected in production. | . Windows password setup . Before enabling windows bots on Google Compute Engine, you need to set the administrator password in the windows-password metadata attribute. The password must satisfy the windows password policy requirements. To set it, run: . gcloud compute project-info add-metadata \\ --metadata-from-file=windows-password=/path/to/password-file --project=$CLOUD_PROJECT_ID . This allows you to connect via remote desktop into your windows bots with the clusterfuzz username (admin) and your configured password. Deploying new changes . Read the instructions here to deploy new changes. ",
    "url": "/clusterfuzz-document-cn/production-setup/setting-up-bots/#configuration",
    "relUrl": "/production-setup/setting-up-bots/#configuration"
  },"118": {
    "doc": "Setting up bots",
    "title": "Verification",
    "content": "Google Compute Engine bots . Once deployed, bots are automatically created via an App Engine cron task that runs every 30 minutes. For faster results, you can manually force it by visiting the Cron jobs page here and running the /manage-vms cron job. After the cron job finishes, check this page to ensure that all instances are created for this particular instance group. If you see a spinning circle next to the instance group, for longer than a few minutes, it can indicate that an error occurred. You can click the instance group name to see the error message (e.g. insufficient resource quota). Note: The default quota for compute resources such as “CPUs”, “In-use IP addresses” and “Persistent Disk Standard (GB)” might be insufficient for your fuzzing cluster needs. You can check your current quota here and request more resources as needed. Non-Google Compute Engine bots . These bots should start within a minute after the startup script finishes execution (e.g. $CONFIG_DIR/bot/setup/mac.bash for macOS). You can verify the bots started by checking that their hostnames show up on the Bots page. ",
    "url": "/clusterfuzz-document-cn/production-setup/setting-up-bots/#verification",
    "relUrl": "/production-setup/setting-up-bots/#verification"
  },"119": {
    "doc": "Setting up fuzzing",
    "title": "Setting up fuzzing",
    "content": "以下页面将引导您设置模糊测试任务. ClusterFuzz支持这两种类型的模糊测试: 覆盖率导向的模糊测试(使用libFuzzer以及AFL)以及黑盒模糊测试. 查看这个页面以获悉这两种类型的比较. ",
    "url": "/clusterfuzz-document-cn/setting-up-fuzzing/",
    "relUrl": "/setting-up-fuzzing/"
  },"120": {
    "doc": "Source code",
    "title": "Source code",
    "content": ". | Source code . | Directory structure | . | . ",
    "url": "/clusterfuzz-document-cn/contributing-code/source-code/",
    "relUrl": "/contributing-code/source-code/"
  },"121": {
    "doc": "Source code",
    "title": "Directory structure",
    "content": ". | bot - 放置bot特定文件(例如fuzzers, corpora)的目录. | configs -示例项目配置, 也用于测试. | coverage - 用于存储测试的覆盖率数据的目录. | deployment - 存储部署相关的文件, 例如源代码归档. | docker - 示例Docker映像示例, 测试于Google Cloud VMs. | docs - 本文档. | local - 用于本地测试的文件(例如, 用于安装ClusterFuzz依赖项的install_deps.bash). | resources - Bots所需的辅助用二进制文件(例如llvm-symbolizer). | src - 源代码根目录. | appengine - App Engine相关代码/文件(Python 2) . | handlers - 各种网页的后端代码. | libs - 通用的辅助用代码库(例如访问控制). | private - 各种网页的原始模板代码(Polymer 2) | templates - 用于自动生成各种网页的最小模板代码(Polymer 2). | . | go - Go语言代码. | python - Python 2代码. | bot - Bot相关代码. | tests - 核心代码和App Engine代码的单元测试集. | 其余的是代码包package级别的目录. | . | third_party - 依赖的第三方软件包. | requirements.txt - 平台无关的依赖包清单(Python 2). | platform_requirements.txt - (Python 2). 平台相关的依赖包清单(Python 2). | . | bower.json - 用于Polymer 2的组件依赖. | butler.py - 用于各种命令行任务(例如测试, 部署)的帮助程序脚本. | . ",
    "url": "/clusterfuzz-document-cn/contributing-code/source-code/#directory-structure",
    "relUrl": "/contributing-code/source-code/#directory-structure"
  },"122": {
    "doc": "Staging changes",
    "title": "Staging changes",
    "content": "建议先暂存(stage)在App Engine或Bot上进行的代码改动, 然后再将其部署到生产环境中. 这样有助于在大规模部署这些改动之前, 获得这些改动的造成的影响. | Staging changes . | Prerequisites | App Engine changes | Bot changes | . | . ",
    "url": "/clusterfuzz-document-cn/contributing-code/staging-changes/",
    "relUrl": "/contributing-code/staging-changes/"
  },"123": {
    "doc": "Staging changes",
    "title": "Prerequisites",
    "content": ". | 您首先需要参照生产设置篇章部署好一个环境. | . ",
    "url": "/clusterfuzz-document-cn/contributing-code/staging-changes/#prerequisites",
    "relUrl": "/contributing-code/staging-changes/#prerequisites"
  },"124": {
    "doc": "Staging changes",
    "title": "App Engine changes",
    "content": "您可以使用以下命令在暂存服务器实例上测试UI或Cron的改动: . python butler.py deploy --staging --config-dir=$CONFIG_DIR . 部署后, 可以前往https://staging-dot-&lt;your project id&gt;.appspot.com查看您的改动. 注意: 暂存服务器使用与生产服务器相同的数据库. 因此，请注意任何可能影响生产数据库内数据的改动. ",
    "url": "/clusterfuzz-document-cn/contributing-code/staging-changes/#app-engine-changes",
    "relUrl": "/contributing-code/staging-changes/#app-engine-changes"
  },"125": {
    "doc": "Staging changes",
    "title": "Bot changes",
    "content": "您可以使用以下方法在特定的Compute Engine Bot上测试代码改动: . python butler.py remote \\ --instance-name &lt;your instance name&gt; \\ --project &lt;your project id&gt; \\ --zone &lt;your project zone&gt; \\ stage --config-dir=$CONFIG_DIR . 注意: . | 这些更改在2天之内都不会被任何生产部署所覆盖, 以便您有足够的时间来测试您的更改. 如果要放弃这些更改, 只需重新启动Bot即可. | 目前只有通过docker目录所提供的docker映像运行起来的Google Compute Engine Bot才支持此功能. | . ",
    "url": "/clusterfuzz-document-cn/contributing-code/staging-changes/#bot-changes",
    "relUrl": "/contributing-code/staging-changes/#bot-changes"
  },"126": {
    "doc": "Triaging new crashes",
    "title": "Triaging new crashes",
    "content": "ClusterFuzz was built to remove as much manual work from fuzzing as possible. Bug triage, in particular, has historically been a difficult and manual process. This document describes some common workflows where ClusterFuzz may save time with triage. | Triaging new crashes . | Filtering testcases | Regression revision range | Crash stacktrace | Crash statistics | . | . ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/workflows/triaging-new-crashes/",
    "relUrl": "/using-clusterfuzz/workflows/triaging-new-crashes/"
  },"127": {
    "doc": "Triaging new crashes",
    "title": "Filtering testcases",
    "content": "ClusterFuzz performs some analysis on each testcase. For example, ClusterFuzz can determine whether or not a crash has any security implications through its crash type. The Testcases page provides filters and search functionality on testcases. You may filter by: . | crash type | crash state | fuzzer name | job name | Reliability of reproducing the crash | Security implications | . By default, only privileged users may see issues with security implications. This allows you to grant access to some users without leaking potentially sensitive information. See Access control for giving full or more granular access. ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/workflows/triaging-new-crashes/#filtering-testcases",
    "relUrl": "/using-clusterfuzz/workflows/triaging-new-crashes/#filtering-testcases"
  },"128": {
    "doc": "Triaging new crashes",
    "title": "Regression revision range",
    "content": "Though only available for reliably reproducible crashes, the regression range is often the most useful information for triage. It shows the range of commits in which the issue was introduced. The more frequently you create builds, the narrower these ranges will be. If you archive every revision of your build, ClusterFuzz can point to the exact commit which introduced the bug. ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/workflows/triaging-new-crashes/#regression-revision-range",
    "relUrl": "/using-clusterfuzz/workflows/triaging-new-crashes/#regression-revision-range"
  },"129": {
    "doc": "Triaging new crashes",
    "title": "Crash stacktrace",
    "content": "When using sanitizers, the stack traces associated with a bug contain relevant information that can help you determine the cause of the crash. This is more of an art than an exact science, and there is no one process to follow to find a culprit changelist using this information. That said, it is often helpful to look for changes in the regression range, if available, that modify the same files seen in the stack traces. When that isn’t an option, “git blame” or similar tools may be helpful to find a developer more familiar with the code in question who may be a good first point of contact. ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/workflows/triaging-new-crashes/#crash-stacktrace",
    "relUrl": "/using-clusterfuzz/workflows/triaging-new-crashes/#crash-stacktrace"
  },"130": {
    "doc": "Triaging new crashes",
    "title": "Crash statistics",
    "content": "ClusterFuzz also provides statistics on how often issues occur, and under what conditions. For example, ClusterFuzz tracks which platform issues reproduce on and which fuzzers found them. These sometimes provide useful insights for bugs where other methods fail. For example, if nothing directly modifies a file in a crash stack but you find that it only reproduces on a specific platform, a large behavior change on that platform may be the culprit. For a non-reproducible crash, it may be useful to know that it started occurring 3 days ago, the same time as a risky change. ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/workflows/triaging-new-crashes/#crash-statistics",
    "relUrl": "/using-clusterfuzz/workflows/triaging-new-crashes/#crash-statistics"
  },"131": {
    "doc": "UI overview",
    "title": "UI overview",
    "content": "This page gives a brief overview of ClusterFuzz web interface pages. We do not document every page in detail, as the interface is supposed to be intuitive and most page elements have tooltips. 本页简要概述了ClusterFuzz Web界面页面。 我们不会详细记录每个页面，因为该界面应该是直观的，并且大多数页面元素都有工具提示。 . Once you successfully deployed the server (either locally or in production), you should be able to access the following pages. 成功部署服务器（本地或生产环境）后，您应该能够访问以下页面。 . | UI overview . | Testcases | Fuzzer Statistics | Crash Statistics | Upload Testcase | Jobs | Configuration | . | . ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/ui-overview/",
    "relUrl": "/using-clusterfuzz/ui-overview/"
  },"132": {
    "doc": "UI overview",
    "title": "Testcases",
    "content": "This is the default main page. The Testcases page provides information about the issues that were detected by fuzzers running on ClusterFuzz. The page includes various filters as well as a search functionality. 这是默认的主页。 “测试用例”页面提供有关在ClusterFuzz上运行的模糊器检测到的问题的信息。 该页面包括各种过滤器以及搜索功能。 . ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/ui-overview/#testcases",
    "relUrl": "/using-clusterfuzz/ui-overview/#testcases"
  },"133": {
    "doc": "UI overview",
    "title": "Fuzzer Statistics",
    "content": "The Fuzzer Statistics page provides a variety of metrics about performance of the fuzzers. For in-process fuzz targets, the page also provides performance reports and improvement recommendations, as well as links to the metadata associated with a particular fuzz target. “ Fuzzer统计信息”页面提供了有关Fuzzer性能的各种指标。 对于过程中的模糊目标，该页面还提供性能报告和改进建议，以及指向与特定模糊目标相关联的元数据的链接。 . ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/ui-overview/#fuzzer-statistics",
    "relUrl": "/using-clusterfuzz/ui-overview/#fuzzer-statistics"
  },"134": {
    "doc": "UI overview",
    "title": "Crash Statistics",
    "content": "This page provides various statistics about the crashes that were detected by ClusterFuzz. These statistics include frequency of crashes, platforms affected, trends over time. 该页面提供有关ClusterFuzz检测到的崩溃的各种统计信息。 这些统计信息包括崩溃频率，受影响的平台，随时间变化的趋势。 . ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/ui-overview/#crash-statistics",
    "relUrl": "/using-clusterfuzz/ui-overview/#crash-statistics"
  },"135": {
    "doc": "UI overview",
    "title": "Upload Testcase",
    "content": "This page provides a convenient way to upload a single testcase to be tested with a specific target. The most common use case for this is to test a bug that was reported by an external researcher or found by some other system. 该页面提供了一种方便的方式来上传单个测试用例，并通过特定的目标进行测试。 最常见的用例是测试由外部研究人员报告或由其他系统发现的错误。 . ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/ui-overview/#upload-testcase",
    "relUrl": "/using-clusterfuzz/ui-overview/#upload-testcase"
  },"136": {
    "doc": "UI overview",
    "title": "Jobs",
    "content": "This page provides a way to create new or modify existing job configurations. 该页面提供了一种创建新作业或修改现有作业配置的方法。 . ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/ui-overview/#jobs",
    "relUrl": "/using-clusterfuzz/ui-overview/#jobs"
  },"137": {
    "doc": "UI overview",
    "title": "Configuration",
    "content": "This is an administrative page with a variety of settings including ClusterFuzz access control, credentials, etc. This page is available to admin users only. 这是一个具有各种设置的管理页面，包括ClusterFuzz访问控制，凭据等。该页面仅对管理员用户可用。 . ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/ui-overview/#configuration",
    "relUrl": "/using-clusterfuzz/ui-overview/#configuration"
  },"138": {
    "doc": "Uploading a testcase",
    "title": "Uploading a testcase",
    "content": "You may have a testcase that you want to run against your latest production build and check if it crashes. ClusterFuzz provides the Upload Testcase page for this purpose. The Upload Testcase page can run binaries with a testcase and give details about the crash, such as, the crash stacktrace, when the crash was introduced, etc. | Uploading a testcase . | Upload new testcase | Check status | . | . ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/workflows/uploading-a-testcase/",
    "relUrl": "/using-clusterfuzz/workflows/uploading-a-testcase/"
  },"139": {
    "doc": "Uploading a testcase",
    "title": "Upload new testcase",
    "content": "To upload a new testcase: . | Click the “UPLOAD” button. | Archive your testcase locally. | If your testcase is a single file, you can upload as-is. | If your testcase consists of multiple files: . | The main file that is passed to the app must contain run in its name (e.g. run.html). | Bundle all the files in an archive. Supported archive formats include zip and tar. | Exception: If you want to test multiple testcases at once, you don’t need to rename them. Just bundle them in an archive, and select the Test every file in archive independently checkbox in the form. | . | . | Click the “Choose File” button and provide the testcase archive in the file chooser dialog. | Select a Job. This provides information of which build or application to run this testcase against. | If you selected a fuzzing engine job in last step (e.g. libFuzzer, AFL), you would need to provide the name of the fuzz target to use. This is required as an application build can contain multiple fuzz target binaries. | Provide values for any of the other optional fields in the form. Examples: . | You can provide a Commit Position/Revision to run it against a particular revision. This is usually used to check a crash against an older version of the application. | If you want your testcase to be served from a http server, you can check the Load testcase from HTTP server. checkbox. | . | Click the “CREATE” button. | . ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/workflows/uploading-a-testcase/#upload-new-testcase",
    "relUrl": "/using-clusterfuzz/workflows/uploading-a-testcase/#upload-new-testcase"
  },"140": {
    "doc": "Uploading a testcase",
    "title": "Check status",
    "content": "Once you upload a new testcase, you will be redirected to the Testcase Details page for that testcase. This page auto-refreshes every 5 minutes to provide the latest results. At first, ClusterFuzz tries to find if the testcase results in a crash or not. If it does not, ClusterFuzz sets the status of the testcase as Unreproducible. If the testcase does crash, then ClusterFuzz starts with first updating the crash parameters in the *Overview** section and crash stacktrace in the Crash Stacktrace section. Then, ClusterFuzz tries the other tasks such as testcase minimization, finding the regression range, etc. Please be patient to wait on the results. The speed of the results will depend on the availability of bot(s). ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/workflows/uploading-a-testcase/#check-status",
    "relUrl": "/using-clusterfuzz/workflows/uploading-a-testcase/#check-status"
  },"141": {
    "doc": "Using ClusterFuzz",
    "title": "Using ClusterFuzz",
    "content": "这些文档将引导您逐步了解ClusterFuzz的一些关键功能以及常见的工作流程. ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/",
    "relUrl": "/using-clusterfuzz/"
  },"142": {
    "doc": "Workflows",
    "title": "Workflows",
    "content": "这些文档详细介绍了在处理ClusterFuzz发现的崩溃以及分析Fuzzer性能时的一些常见工作流程. ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/workflows/",
    "relUrl": "/using-clusterfuzz/workflows/"
  },"143": {
    "doc": "Workflows",
    "title": "General tips",
    "content": ". | 在查看ClusterFuzz Web页面时, 通常可以将鼠标悬停在项目或字段上(例如, 在Testcase详情页上的”Crash State”)以查看更详细的说明. | . ",
    "url": "/clusterfuzz-document-cn/using-clusterfuzz/workflows/#general-tips",
    "relUrl": "/using-clusterfuzz/workflows/#general-tips"
  }
}
